{"cells":[{"cell_type":"markdown","metadata":{"id":"e460cbb5"},"source":["# About this notebook\n","- Deberta-v3-large starter code\n","- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/pppm-pip-wheels)\n","- Inference notebook is [here](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n","\n","If this notebook is helpful, feel free to upvote :)"]},{"cell_type":"markdown","metadata":{"id":"LY7ihXf3QHH4"},"source":["### embedを得るためのnote"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654440575716,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"VmlmoWLINmmv","outputId":"200bd3b2-ac90-4625-a29a-f4482d818464"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jun  5 14:49:33 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"zULc94aSNyF4"},"source":["# Directory settings"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654440575716,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"fa3b873b"},"outputs":[],"source":["# ====================================================\n","# Directory settings\n","# ====================================================\n","import os\n","import sys\n","import json\n","# INPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\n","# OUTPUT_DIR = './'\n","# if not os.path.exists(OUTPUT_DIR):\n","#     os.makedirs(OUTPUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"1d0c4430"},"source":["# CFG"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654440575716,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"48dd82bb"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    wandb=False\n","    competition='PPPM'\n","    _wandb_kernel='nakama'\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-large\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=500\n","    epochs=4\n","    encoder_lr=1.5e-5\n","    decoder_lr=15e-5 # decoder_lrを10倍してみる\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=32#16\n","    fc_dropout=0.0\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    newtrain = False\n","\n","    name = \"exp019\" # 実験のたびにコピーしてここの名前を変えて実行するとoutputが別のファイルに保存される\n","    api_path = \"/content/drive/MyDrive/kaggle/kaggle.json\"\n","    drive_path = \"/content/drive/MyDrive/kaggle/PPPM\"\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654440575717,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"RuhtrhPoOPiA"},"outputs":[],"source":["COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4081,"status":"ok","timestamp":1654440579795,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"2e07M6l6OOE3","outputId":"136bfc67-5986-4f8c-ba56-b61392c6c933"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kaggle\n","  Downloading kaggle-1.5.12.tar.gz (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 4.8 MB/s \n","\u001b[?25hBuilding wheels for collected packages: kaggle\n","  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=c93988bbe5bc3c6d2f5ea17b8b4df8fdbccdb203bed3803fc774ab9a5133ee5b\n","  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n","Successfully built kaggle\n","Installing collected packages: kaggle\n","  Attempting uninstall: kaggle\n","    Found existing installation: kaggle 1.5.12\n","    Uninstalling kaggle-1.5.12:\n","      Successfully uninstalled kaggle-1.5.12\n","Successfully installed kaggle-1.5.12\n"]}],"source":["!pip install --upgrade --force-reinstall --no-deps kaggle"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24671,"status":"ok","timestamp":1654440604461,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"fjK0B5nGOjSB","outputId":"10541f19-3128-4753-b5e9-7a947259027a"},"outputs":[{"output_type":"stream","name":"stdout","text":["This environment is Google Colab\n","Mounted at /content/drive\n"]}],"source":["if COLAB:\n","    print(\"This environment is Google Colab\")\n","    \n","    # mount\n","    from google.colab import drive\n","    if not os.path.isdir(\"/content/drive\"):\n","        drive.mount('/content/drive') \n","\t\n","    \n","    # use kaggle api (need kaggle token)\n","    f = open(CFG.api_path, 'r')\n","    json_data = json.load(f) \n","    os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","    os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n","    \n","    # set dirs\n","    DRIVE = CFG.drive_path\n","    EXP = CFG.name\n","    INPUT_DIR = os.path.join(DRIVE, \"Input\")\n","    OUTPUT_DIR = os.path.join(DRIVE, \"Output\")\n","    SCRIPT = os.path.join(DRIVE, \"Script\")\n","    OUTPUT_DIR = os.path.join(OUTPUT_DIR, EXP) \n","    # EXP_MODEL = os.path.join(OUTPUT_EXP, \"model\")\n","    # EXP_FIG = os.path.join(OUTPUT_EXP, \"fig\")\n","    # EXP_PREDS = os.path.join(OUTPUT_EXP, \"preds\")\n","\n","    # make dirs\n","    for d in [INPUT_DIR, SCRIPT, OUTPUT_DIR]:\n","        os.makedirs(d, exist_ok=True)\n","\n","    if not os.path.isfile(os.path.join(INPUT_DIR, \"us-patent-phrase-to-phrase-matching.zip\")):\n","        # load dataset\n","        ! kaggle competitions download -c us-patent-phrase-to-phrase-matching -p $INPUT_DIR \n","        unzip_file = os.path.join(INPUT_DIR, 'us-patent-phrase-to-phrase-matching.zip')\n","        ! unzip $unzip_file -d $INPUT_DIR\n","    \n","    if not os.path.isfile(os.path.join(INPUT_DIR, \"cpc-data.zip\")):\n","        # load dataset\n","        ! kaggle datasets download -d yasufuminakama/cpc-data -p $INPUT_DIR\n","        unzip_file = os.path.join(INPUT_DIR, 'cpc-data.zip')\n","        ! unzip $unzip_file -d $INPUT_DIR\n","\n","else:\n","    print(\"This environment is Kaggle Kernel\")\n","    \n","    # set dirs\n","    INPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\n","    OUTPUT_DIR = './'\n","    \n","    \n","    # # copy dirs\n","    # if Config.kaggle_dataset_path is not None:\n","    #     KD_MODEL = os.path.join(Config.kaggle_dataset_path, \"model\")\n","    #     KD_EXP_PREDS = os.path.join(Config.kaggle_dataset_path, \"preds\")\n","    #     shutil.copytree(KD_MODEL, EXP_MODEL)\n","    #     shutil.copytree(KD_EXP_PREDS, EXP_PREDS)\n","\n","    # # make dirs\n","    # for d in [EXP_MODEL, EXP_FIG, EXP_PREDS]:\n","    #     os.makedirs(d, exist_ok=True)\n","        \n","    "]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654440604462,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"b88c983e"},"outputs":[],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    \n","    import wandb\n","\n","    try:\n","        from kaggle_secrets import UserSecretsClient\n","        user_secrets = UserSecretsClient()\n","        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        wandb.login(key=secret_value_0)\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project='PPPM-Public', \n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=CFG.model,\n","                     job_type=\"train\",\n","                     anonymous=anony)"]},{"cell_type":"markdown","metadata":{"id":"f2ed8ef2"},"source":["# Library"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33792,"status":"ok","timestamp":1654440638250,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"35916341","outputId":"7322e4d6-ba70-4cb6-c173-069014391dde"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.__version__: 1.11.0+cu113\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers[sentencepiece]\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 11.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 31.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 10.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.11.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 4.2 MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 30.8 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.8.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, sentencepiece\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.19.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers==0.12.1 in /usr/local/lib/python3.7/dist-packages (0.12.1)\n","tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.19.2\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, StratifiedGroupKFold\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","# !pip install transformers==4.18.0\n","!pip install transformers[sentencepiece]\n","!pip install tokenizers==0.12.1\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","import lightgbm as lgb\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"fd586614"},"source":["# Utils"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654440638250,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"d5c0ccc6"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = sp.stats.pearsonr(y_true, y_pred)[0]\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'/train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"cb3d8e1e"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1433,"status":"ok","timestamp":1654440639677,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"bef012d3"},"outputs":[],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv(INPUT_DIR+'/train.csv')\n","test = pd.read_csv(INPUT_DIR+'/test.csv')\n","submission = pd.read_csv(INPUT_DIR+'/sample_submission.csv')\n","# print(f\"train.shape: {train.shape}\")\n","# print(f\"test.shape: {test.shape}\")\n","# print(f\"submission.shape: {submission.shape}\")\n","# display(train.head())\n","# display(test.head())\n","# display(submission.head())"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654440639679,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"AqzuRHB_NyGF"},"outputs":[],"source":["# ====================================================\n","# CPC Data\n","# ====================================================\n","# def get_cpc_texts():\n","#     contexts = []\n","#     pattern = '[A-Z]\\d+'\n","#     if COLAB:\n","#         cpcpath = os.path.join(INPUT_DIR, 'CPCSchemeXML202105')\n","#     else:\n","#         cpcpath = '../input/cpc-data/CPCSchemeXML202105'\n","#     for file_name in os.listdir(cpcpath):\n","#         result = re.findall(pattern, file_name)\n","#         if result:\n","#             contexts.append(result)\n","#     contexts = sorted(set(sum(contexts, [])))\n","#     results = {}\n","#     for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","#         if COLAB:\n","#             cpcpath = os.path.join(INPUT_DIR, f'CPCTitleList202202/cpc-section-{cpc}_20220201.txt')\n","#         else:\n","#             cpcpath = f'../input/cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt'\n","#         with open(cpcpath) as f:\n","#             s = f.read()\n","#         pattern = f'{cpc}\\t\\t.+'\n","#         result = re.findall(pattern, s)\n","#         cpc_result = result[0].lstrip(pattern)\n","#         for context in [c for c in contexts if c[0] == cpc]:\n","#             pattern = f'{context}\\t\\t.+'\n","#             result = re.findall(pattern, s)\n","#             results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","#     return results\n","\n","\n","# cpc_texts = get_cpc_texts()\n","# torch.save(cpc_texts, OUTPUT_DIR+\"/cpc_texts.pth\")\n","# train['context_text'] = train['context'].map(cpc_texts)\n","# test['context_text'] = test['context'].map(cpc_texts)\n","# display(train.head())\n","# display(test.head())"]},{"cell_type":"code","source":["path = os.path.join(INPUT_DIR, 'titles.csv')\n","title = pd.read_csv(path)\n","def get_first_slice(text):\n","    texts = text.split(';')\n","    return texts[0]\n","\n","def add_cpc(test):\n","    test = test.merge(title, left_on='context', right_on='code')\n","\n","    detail_dict = dict(zip(title['code'], title['title']))\n","    test['section'] = test['context'].map(lambda x: str(x)[0])\n","\n","    test['context_text'] = test['context'].map(lambda x: detail_dict[x])\n","    test['section_text'] = test['section'].map(lambda x: detail_dict[x])\n","\n","    test['context_text'] = test['context_text'].map(get_first_slice)\n","    test['section_text'] = test['section_text'].map(get_first_slice)\n","    test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]' + test['section_text'] + '.' + test['context_text']\n","    return test\n","\n","train = add_cpc(train)\n","test = add_cpc(test)"],"metadata":{"id":"s3q5DZ4iQYgJ","executionInfo":{"status":"ok","timestamp":1654440642507,"user_tz":-540,"elapsed":2834,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654440642508,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"uSqmGITONyGG"},"outputs":[],"source":["# train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n","# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n","# display(train.head())\n","# display(test.head())"]},{"cell_type":"markdown","metadata":{"id":"uYPq-UFTNyGH"},"source":["# EDA"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654440642508,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"wcCwUv5eNyGH"},"outputs":[],"source":["# train['score'].hist()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654440642508,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"vob-KqQINyGH"},"outputs":[],"source":["# display(train['context'].apply(lambda x: x[0]).value_counts())"]},{"cell_type":"markdown","metadata":{"id":"VJIOGLybNyGI"},"source":["- Y is not in training data, but may be in test data?"]},{"cell_type":"markdown","metadata":{"id":"9e05b6c4"},"source":["# CV split"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654440642509,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"4ZMUtDpFO5K8","outputId":"b626bde1-d725-4d28-e93b-29776aa6a707"},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3648\n","1    3648\n","2    3648\n","3    3647\n","4    3647\n","5    3647\n","6    3647\n","7    3647\n","8    3647\n","9    3647\n","dtype: int64"]},"metadata":{}}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654440642510,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"TB-cGGuQ-Qi9"},"outputs":[],"source":["# # ====================================================\n","# # CV split\n","# # ====================================================\n","# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","# Fold = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'], train['anchor'])):\n","#     train.loc[val_index, 'fold'] = int(n)\n","# train['fold'] = train['fold'].astype(int)\n","# display(train.groupby('fold').size())"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654440642510,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"4c3ce877"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"918a28aa"},"source":["# tokenizer"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["388cc5bb0d4744d2b3bdc58bacdaa79b","d7548e52829d45189a2669ffb65283d6","c75e748d11f54696891ce1c02d0cd90d","eb37b781e3894178b300efd102cccc4b","3c1c2a8164eb459793880e74e9cff940","4709a2da3e784e9fa7916030c8a42591","34688dff697e4365875e00bf9f81898c","4e29da437a084a5695cde86a26bfd566","e9894e50a0574fb5a250b6ec5a727ea2","95fdb51dc98c449ab92ba001a51bfd02","aba322c0d19548679e23ae05cacc38ca","efebe0e47c284509a961cd3a2b8a425a","0b44e84feaaa48b89083b86e4dceaaee","c75302f1bf9b493cb380368c8c350f77","127bc45e8c4f4ccb8ff1918d39749439","e85de0dd0ae1470ebacb398c6a400987","d2386f21bc9f42e3a2ba37abef6d171c","3fc343960ea74699b5d36b944a215336","8f29759c12b849aa8adb1c11a1fb1e92","f171e5f46bc84b2ea533e5705ad519d0","d0a036f4da2b439abd66d338e15d1df6","8e28220377fc405ea82febb190425d61","f2ae7ed3c7694024b6f8697982324391","e1b20f06653b48018be12077706fe0ad","0d1a2b4a47d547f298c99f731d0d4fc7","fd0adb1ee69b4fb287572cd12d2b7162","95be8e0c3992451bbf698c668fb5cc89","a3f8ea70e64e46c5b36587b35970b52c","d627f4dede75400aabae4c5bfb610b12","7db990dcd612470789f4b56793ee4b29","9c8464542d904436a0fd5add7fa51fae","9e10c0f2aa8047e4bbd33c3dfc5df4a3","c20396bc7d844d00b0eafec48c9c316a"]},"executionInfo":{"elapsed":12590,"status":"ok","timestamp":1654440655093,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"KCSjp89kNyGJ","outputId":"0cf88265-7ae1-43bc-a017-2f9d35c726ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"388cc5bb0d4744d2b3bdc58bacdaa79b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efebe0e47c284509a961cd3a2b8a425a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2ae7ed3c7694024b6f8697982324391"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","! pip install sentencepiece\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'/tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"14da40cf"},"source":["# Dataset"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163,"referenced_widgets":["58045be8708147ccad087ea96543fc63","29291a37050b4e149e4d31d3b86c798b","5e3cfa7f20aa4d27a5b8b58f2a63aecb","084b90ae4d074f7a81d5b9868b0d01f0","edd12735f0254c77a377bb762e584ca2","e6ea6447019844dc99f93f88ce0e4a0b","7cfa1f4a74884c73a7a367b993da3162","8a199c0fdf524a99b0d420430fbb642d","6b0c3ee129724000b582ad4d79704eee","8a246a817907421d9476cd81d88fa0b5","dd7b9212a065445697ba1cd333dd6d64","6de33cc1c0634eed96693db8d5c7634e","67787fd8acf74c0bae0ccdc5f3e6b1e9","e64cec66571c4e56b17d0ee2fe2f9f51","29708ec2a2d7493d9bbc08cdc31e8f46","3c63df8931da4bb6a5f35600825f0e82","c1cac53be3584725bb6d4716a12fafb8","182ff7ab057245128956b2ea65e910df","c664034e29e341a6a169f9c1586c08e9","85cae7be4aae495694a0fe3ae4a3ff95","d4b050c1044d45aa87899d7f5335f3bd","25d1131fa6964471809a73923b1af45f","972ea9d4061c4e5cb2042312b98a771a","734df4ac8ed947df9606c8a961096164","c873bdb7217e417ab118bbfbb79c990a","2d99eba6bbe54240af5e37daf03d503a","54ac6a1c01ff4ce6a3426067f0073bca","ea8e48675abd44899ca708968dd91356","2f0fd9f0c67441279dba32068dc2f955","7b9aeeb1a5794964bd2e89ae50ffbe8a","c1906b2f85d94ef4888196cc6ebf30d0","932843b6af8447d5b883f7477a8b8fa9","56e628ddcccf4b77b4501f9ee1756a10","a13ac523446b49feaabd97f0827918d6","30dfc6a1d3174e7dacb42b67e16f630c","2da9f7d6ff174b6da557d53a0fa4c393","b06ca09cac1047babbe14495d00441ee","07411170b52643978bc9fd4b7da11fba","47dc8bbcc4b443a697b21d38480951cf","6078240c0d7f4feaa000f91260dda579","97e8ffc0de8c4a3e88136aa8a2cbca34","4a762a66f7f542e197d4a8b700877a19","f481e09252564143bb1ca5a804117fc8","28972586d7794c5db54feb5ae98f77ba"]},"executionInfo":{"elapsed":37194,"status":"ok","timestamp":1654440692276,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"c00327b0","outputId":"1800d9ba-117f-4e13-9abb-56ac3cf52c90"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/36473 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58045be8708147ccad087ea96543fc63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/36473 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6de33cc1c0634eed96693db8d5c7634e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/36473 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"972ea9d4061c4e5cb2042312b98a771a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/36473 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a13ac523446b49feaabd97f0827918d6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_len: 70\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths_dict = {}\n","\n","lengths = []\n","# tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n","# for text in tk0:\n","#     length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","#     lengths.append(length)\n","# lengths_dict['context_text'] = lengths\n","\n","for text_col in ['anchor', 'target', 'context_text', 'section_text']:\n","    lengths = []\n","    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        lengths.append(length)\n","    lengths_dict[text_col] = lengths\n","    \n","CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n","                + max(lengths_dict['context_text']) + 5 # CLS + SEP + SEP + SEP + .\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1654440692277,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"9f791a19"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1654440692277,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"a200bd5b","outputId":"b85e13ed-e5d4-4dda-a7a0-94f11b573e05"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntrain_dataset = TrainDataset(CFG, train)\\ninputs, label = train_dataset[0]\\nprint(inputs)\\nprint(label)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}],"source":["\"\"\"\n","train_dataset = TrainDataset(CFG, train)\n","inputs, label = train_dataset[0]\n","print(inputs)\n","print(label)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"e04d6363"},"source":["# Model"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1654440692278,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"2mLyXDgoHwmQ"},"outputs":[],"source":["class TransformerHead(nn.Module):\n","    def __init__(self, in_features, max_length, num_layers=1, nhead=8, num_targets=1):\n","        super().__init__()\n","        # in_features は各トークンに対するベクトルの次元数\n","        # max_length は最大トークン数\n","        self.transformer = nn.TransformerEncoder(encoder_layer=nn.TransformerEncoderLayer(d_model=in_features,\n","                                                                                          nhead=nhead),\n","                                                 num_layers=num_layers)\n","        self.row_fc = nn.Linear(in_features, 1)\n","        self.out_features = max_length\n","\n","    def forward(self, x):\n","        out = self.transformer(x)\n","        out = self.row_fc(out).squeeze(-1)\n","        return out"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1654440692278,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"4c5bab44"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        \n","        in_features = self.config.hidden_size\n","        self.attention = TransformerHead(in_features=in_features, max_length=cfg.max_len, num_layers=1, nhead=8, num_targets=1)\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.attention.out_features, self.cfg.target_size)\n","        self._init_weights(self.fc)\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        # feature = torch.mean(last_hidden_states, 1)\n","        feature = self.attention(last_hidden_states)\n","        \n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","#         print(feature.shape)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output, feature"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1654440692279,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"Q6jysiLTMiUN"},"outputs":[],"source":["class Pearson_Loss(nn.Module):\n","    def __init__(self):\n","        super(Pearson_Loss, self).__init__()\n","\n","    def forward(self, label, preds):\n","        preds_mean = torch.mean(preds)\n","        label_mean = torch.mean(label)\n","\n","        num = torch.sum(torch.mul((preds-preds_mean),(label-label_mean)))\n","\n","        pred_std = torch.sum(torch.square((preds-preds_mean)))\n","        label_std = torch.sum(torch.square((label-label_mean)))\n","        den = torch.sqrt(pred_std * label_std)\n","        loss = 1-torch.divide(num, den)\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"deee9675"},"source":["# Helpler functions"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1654440692279,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"c8263b0c"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterions, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds, _ = model(inputs)\n","        # loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        loss = 0\n","        for criterion in criterions:\n","            loss += criterion(y_preds.view(-1, 1).to(torch.half), labels.view(-1, 1).to(torch.half))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterions, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds, _ = model(inputs)\n","        # loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        loss = 0\n","        for criterion in criterions:\n","            loss += criterion(y_preds.view(-1, 1).to(torch.half), labels.view(-1, 1).to(torch.half))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds, _ = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":848,"status":"ok","timestamp":1654440693115,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"ovXqVJlFLdMj"},"outputs":[],"source":["### lightgbm\n","### 適当なやつ\n","def train_fn_(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    from lightgbm import LGBMRegressor\n","    model.eval()\n","\n","    embeds = []\n","    targets = []\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        with torch.no_grad():\n","            y_preds, embed = model(inputs)\n","        embeds.append(embed.to('cpu').numpy())\n","        targets.append(labels.to('cpu').numpy())\n","    embeds = np.concatenate(embeds) # (datasize, 768)\n","    targets = np.concatenate(targets) # (datasize, 1)\n","    \n","    params = {\n","    'objective': 'regression',\n","    'boosting_type': 'gbdt',  # default = 'gbdt'\n","    'num_leaves': 2**8-1, #63,         # default = 31,\n","    'learning_rate': 0.01,    # default = 0.1\n","    'feature_fraction': 0.8,  # default = 1.0\n","    'bagging_freq': 1,        # default = 0\n","    'bagging_fraction': 0.8,  # default = 1.0\n","    'random_state': 0,        # default = None\n","    'max_depth': 8,\n","#     'min_data_in_leaf': 50,   # default = 20\n","    'verbosity': -1,\n","}\n","    \n","\n","    train_data = lgb.Dataset(\n","        data=embeds, \n","        label=targets, \n","    )\n","\n","    bst = lgb.train(params=params, \n","                    train_set=train_data, \n","                    num_boost_round=600)\n","\n","    return bst, embeds, targets\n","\n","def valid_fn_(valid_loader, model, criterion, device, gbdt):\n","    model.eval()\n","    preds = []\n","    embeds = []\n","    targets = []\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        with torch.no_grad():\n","            _, embed = model(inputs)\n","        embeds.append(embed.to('cpu').numpy())\n","        targets.append(labels.to('cpu').numpy())\n","\n","        y_preds = gbdt.predict(embed.to('cpu').numpy())\n","        preds.append(y_preds)\n","\n","    predictions = np.concatenate(preds)\n","    embeds = np.concatenate(embeds) # (datasize, 768)\n","    targets = np.concatenate(targets) # (datasize, 1)\n","#     predictions = np.concatenate(predictions)\n","    return predictions, embeds, targets\n","\n","\n","# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['score'].values\n","\n","    # newtrain ============================================\n","    if CFG.newtrain:\n","        path = os.path.join(INPUT_DIR, 'newtrain.csv')\n","        df = pd.read_csv(path)\n","        r = [0.95, 0.97, 0.7, 0.60, 0.98]\n","        m = ['0', '1', '2', '3', '4']\n","        new_df = []\n","        for i, j in zip(m, r):\n","            idx = df[i] > j\n","            df.loc[idx, 'score'] = int(i) * 0.25\n","            new_df.append(df[idx])\n","        new_train = pd.concat(new_df)\n","        train_folds = pd.concat([train_folds[['text', 'score']], new_train[['text', 'score']]])\n","    # ======================================================\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    model.config.update(\n","        {\n","            \"attention_probs_dropout_prob\" : 0.0,\n","            \"hidden_dropout_prob\": 0.0\n","        }\n","    )\n","    torch.save(model.config, OUTPUT_DIR+'/config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = [nn.BCEWithLogitsLoss(reduction=\"mean\"), nn.MSELoss(reduction='mean'), Pearson_Loss()]\n","    \n","    best_score = 0.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","        \n","        # lightgbm train\n","        gbdt, embeds_tr, targets_tr = train_fn_(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        predictions, embeds_va, targets_va = valid_fn_(valid_loader, model, criterion, device, gbdt)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","#         LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if best_score < score:\n","            best_score = score\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","            gbdt.save_model(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_best_gbdt.txt\")\n","        \n","            np.save(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_embeds_tr\", embeds_tr)\n","            np.save(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_targets_tr\", targets_tr)\n","            np.save(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_embeds_va\", embeds_va)\n","            np.save(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_targets_va\", targets_va)\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions'] #bestmodelのpredictionをとりだす\n","    ### round\n","#     predictions *= 4\n","#     predictions = predictions.round() / 4\n","    valid_folds['pred'] = predictions\n","    valid_folds['pred'].hist(bins=100)\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["373615ca39dc49ea84ba10916caf03d1","6508314fe7b045cf805287982ffef5b2","d320153c927b484683c940c60ed1ab9e","daa46be7d90c4dada74093dbb5b1b126","76ade73eddda433e8ca10fc17562ab81","9600ad091a5b41cba70300c646c2be94","a7cb223076e9495eb35736168fa5ff17","2a6674747b6c46e596d2d0e4645ef51e","6aa2ea76437e422cb3ab1e4a6287d3b0","2f8bbd195e2a4939a5509c43b861207b","0a03cd32416e4e2396cf0d25d0584b2c"]},"id":"6cc76b1e","executionInfo":{"status":"ok","timestamp":1654463187767,"user_tz":-540,"elapsed":22494661,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"}},"outputId":"6566a612-4cd8-4a0d-9625-02c005e4caad"},"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/833M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"373615ca39dc49ea84ba10916caf03d1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1025] Elapsed 0m 2s (remain 34m 37s) Loss: 1.7471(1.7471) Grad: nan  LR: 0.00000003  \n","Epoch: [1][100/1025] Elapsed 1m 42s (remain 15m 39s) Loss: 1.1797(1.5920) Grad: 89236.2188  LR: 0.00000303  \n","Epoch: [1][200/1025] Elapsed 3m 23s (remain 13m 54s) Loss: 1.1113(1.3948) Grad: 63554.4883  LR: 0.00000603  \n","Epoch: [1][300/1025] Elapsed 5m 4s (remain 12m 11s) Loss: 1.0010(1.2754) Grad: 24777.0508  LR: 0.00000903  \n","Epoch: [1][400/1025] Elapsed 6m 44s (remain 10m 30s) Loss: 1.0762(1.2044) Grad: 22636.7227  LR: 0.00001203  \n","Epoch: [1][500/1025] Elapsed 8m 25s (remain 8m 48s) Loss: 1.1641(1.1539) Grad: 32305.4238  LR: 0.00001500  \n","Epoch: [1][600/1025] Elapsed 10m 5s (remain 7m 7s) Loss: 1.0918(1.1169) Grad: 24203.8438  LR: 0.00001497  \n","Epoch: [1][700/1025] Elapsed 11m 45s (remain 5m 26s) Loss: 0.8608(1.0898) Grad: 17164.9922  LR: 0.00001489  \n","Epoch: [1][800/1025] Elapsed 13m 25s (remain 3m 45s) Loss: 0.7866(1.0698) Grad: 12653.4336  LR: 0.00001474  \n","Epoch: [1][900/1025] Elapsed 15m 6s (remain 2m 4s) Loss: 0.8672(1.0541) Grad: 14606.7373  LR: 0.00001455  \n","Epoch: [1][1000/1025] Elapsed 16m 46s (remain 0m 24s) Loss: 0.7881(1.0376) Grad: 12473.4980  LR: 0.00001430  \n","Epoch: [1][1024/1025] Elapsed 17m 10s (remain 0m 0s) Loss: 0.8159(1.0346) Grad: 8563.6367  LR: 0.00001423  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Score: 0.8466\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/1025] Elapsed 0m 1s (remain 21m 40s) Loss: 0.9023(0.9023) Grad: nan  LR: 0.00001422  \n","Epoch: [2][100/1025] Elapsed 1m 41s (remain 15m 31s) Loss: 0.9375(0.8419) Grad: 72981.8203  LR: 0.00001391  \n","Epoch: [2][200/1025] Elapsed 3m 21s (remain 13m 47s) Loss: 0.8701(0.8447) Grad: 24008.4551  LR: 0.00001355  \n","Epoch: [2][300/1025] Elapsed 5m 1s (remain 12m 6s) Loss: 0.8110(0.8410) Grad: 197418.6406  LR: 0.00001314  \n","Epoch: [2][400/1025] Elapsed 6m 42s (remain 10m 25s) Loss: 0.9302(0.8412) Grad: 46130.3984  LR: 0.00001269  \n","Epoch: [2][500/1025] Elapsed 8m 22s (remain 8m 45s) Loss: 0.8389(0.8437) Grad: 309756.8125  LR: 0.00001219  \n","Epoch: [2][600/1025] Elapsed 10m 2s (remain 7m 4s) Loss: 0.7637(0.8442) Grad: 20179.5391  LR: 0.00001167  \n","Epoch: [2][700/1025] Elapsed 11m 42s (remain 5m 24s) Loss: 0.7856(0.8412) Grad: 31668.4570  LR: 0.00001111  \n","Epoch: [2][800/1025] Elapsed 13m 22s (remain 3m 44s) Loss: 0.7949(0.8390) Grad: 23372.2812  LR: 0.00001052  \n","Epoch: [2][900/1025] Elapsed 15m 2s (remain 2m 4s) Loss: 0.8477(0.8401) Grad: 14210.6260  LR: 0.00000991  \n","Epoch: [2][1000/1025] Elapsed 16m 42s (remain 0m 24s) Loss: 0.8525(0.8390) Grad: 15614.2881  LR: 0.00000928  \n","Epoch: [2][1024/1025] Elapsed 17m 6s (remain 0m 0s) Loss: 0.8062(0.8388) Grad: 24149.9160  LR: 0.00000913  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Score: 0.8578\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/1025] Elapsed 0m 1s (remain 21m 52s) Loss: 0.7720(0.7720) Grad: nan  LR: 0.00000913  \n","Epoch: [3][100/1025] Elapsed 1m 42s (remain 15m 36s) Loss: 0.7964(0.7993) Grad: 81860.6172  LR: 0.00000848  \n","Epoch: [3][200/1025] Elapsed 3m 22s (remain 13m 51s) Loss: 0.7349(0.7990) Grad: 32953.4258  LR: 0.00000783  \n","Epoch: [3][300/1025] Elapsed 5m 3s (remain 12m 9s) Loss: 0.8379(0.7984) Grad: 65264.6641  LR: 0.00000718  \n","Epoch: [3][400/1025] Elapsed 6m 43s (remain 10m 27s) Loss: 0.7651(0.7963) Grad: 16357.9590  LR: 0.00000653  \n","Epoch: [3][500/1025] Elapsed 8m 23s (remain 8m 46s) Loss: 0.7778(0.7967) Grad: 16864.6211  LR: 0.00000588  \n","Epoch: [3][600/1025] Elapsed 10m 3s (remain 7m 6s) Loss: 0.7046(0.7954) Grad: 13171.2842  LR: 0.00000525  \n","Epoch: [3][700/1025] Elapsed 11m 44s (remain 5m 25s) Loss: 0.7622(0.7943) Grad: 23650.5645  LR: 0.00000464  \n","Epoch: [3][800/1025] Elapsed 13m 24s (remain 3m 44s) Loss: 0.8184(0.7938) Grad: 35082.4414  LR: 0.00000404  \n","Epoch: [3][900/1025] Elapsed 15m 4s (remain 2m 4s) Loss: 0.7236(0.7929) Grad: 15963.8652  LR: 0.00000348  \n","Epoch: [3][1000/1025] Elapsed 16m 44s (remain 0m 24s) Loss: 0.8760(0.7925) Grad: 27641.7266  LR: 0.00000294  \n","Epoch: [3][1024/1025] Elapsed 17m 8s (remain 0m 0s) Loss: 0.7412(0.7919) Grad: 19744.2324  LR: 0.00000282  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Score: 0.8705\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/1025] Elapsed 0m 1s (remain 22m 33s) Loss: 0.7969(0.7969) Grad: nan  LR: 0.00000281  \n","Epoch: [4][100/1025] Elapsed 1m 42s (remain 15m 35s) Loss: 0.7661(0.7814) Grad: 76760.4062  LR: 0.00000232  \n","Epoch: [4][200/1025] Elapsed 3m 22s (remain 13m 51s) Loss: 0.7124(0.7739) Grad: 47402.2266  LR: 0.00000187  \n","Epoch: [4][300/1025] Elapsed 5m 3s (remain 12m 9s) Loss: 0.6895(0.7725) Grad: 72968.2031  LR: 0.00000146  \n","Epoch: [4][400/1025] Elapsed 6m 43s (remain 10m 27s) Loss: 0.7520(0.7722) Grad: 70498.8047  LR: 0.00000109  \n","Epoch: [4][500/1025] Elapsed 8m 23s (remain 8m 46s) Loss: 0.7031(0.7698) Grad: 40277.6055  LR: 0.00000078  \n","Epoch: [4][600/1025] Elapsed 10m 3s (remain 7m 5s) Loss: 0.7627(0.7687) Grad: 100688.3750  LR: 0.00000051  \n","Epoch: [4][700/1025] Elapsed 11m 44s (remain 5m 25s) Loss: 0.7500(0.7682) Grad: 58423.9492  LR: 0.00000030  \n","Epoch: [4][800/1025] Elapsed 13m 24s (remain 3m 44s) Loss: 0.6973(0.7688) Grad: 60393.0312  LR: 0.00000015  \n","Epoch: [4][900/1025] Elapsed 15m 4s (remain 2m 4s) Loss: 0.7803(0.7689) Grad: 67529.7891  LR: 0.00000005  \n","Epoch: [4][1000/1025] Elapsed 16m 44s (remain 0m 24s) Loss: 0.7021(0.7679) Grad: 35130.4805  LR: 0.00000000  \n","Epoch: [4][1024/1025] Elapsed 17m 8s (remain 0m 0s) Loss: 0.7358(0.7681) Grad: 120007.1953  LR: 0.00000000  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - Score: 0.8711\n","========== fold: 0 result ==========\n","Score: 0.8711\n","========== fold: 1 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1025] Elapsed 0m 3s (remain 54m 6s) Loss: 1.8711(1.8711) Grad: nan  LR: 0.00000003  \n","Epoch: [1][100/1025] Elapsed 1m 43s (remain 15m 47s) Loss: 1.5820(1.7295) Grad: 106786.0156  LR: 0.00000303  \n","Epoch: [1][200/1025] Elapsed 3m 23s (remain 13m 55s) Loss: 0.9746(1.4559) Grad: 54080.9453  LR: 0.00000603  \n","Epoch: [1][300/1025] Elapsed 5m 3s (remain 12m 11s) Loss: 0.9668(1.3134) Grad: 22980.8594  LR: 0.00000903  \n","Epoch: [1][400/1025] Elapsed 6m 44s (remain 10m 28s) Loss: 0.8579(1.2319) Grad: 10460.3438  LR: 0.00001203  \n","Epoch: [1][500/1025] Elapsed 8m 24s (remain 8m 47s) Loss: 1.0723(1.1777) Grad: 14039.6426  LR: 0.00001500  \n","Epoch: [1][600/1025] Elapsed 10m 4s (remain 7m 6s) Loss: 0.9639(1.1381) Grad: 11142.6914  LR: 0.00001497  \n","Epoch: [1][700/1025] Elapsed 11m 44s (remain 5m 25s) Loss: 0.7681(1.1101) Grad: 6646.0371  LR: 0.00001489  \n","Epoch: [1][800/1025] Elapsed 13m 25s (remain 3m 45s) Loss: 1.0586(1.0862) Grad: 10540.0596  LR: 0.00001474  \n","Epoch: [1][900/1025] Elapsed 15m 5s (remain 2m 4s) Loss: 0.7388(1.0682) Grad: 4203.5142  LR: 0.00001455  \n","Epoch: [1][1000/1025] Elapsed 16m 45s (remain 0m 24s) Loss: 0.9609(1.0509) Grad: 12914.2646  LR: 0.00001430  \n","Epoch: [1][1024/1025] Elapsed 17m 9s (remain 0m 0s) Loss: 0.6997(1.0465) Grad: 3641.9016  LR: 0.00001423  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Score: 0.8396\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/1025] Elapsed 0m 1s (remain 22m 25s) Loss: 0.7280(0.7280) Grad: nan  LR: 0.00001422  \n","Epoch: [2][100/1025] Elapsed 1m 42s (remain 15m 37s) Loss: 0.8413(0.8664) Grad: 90812.3984  LR: 0.00001391  \n","Epoch: [2][200/1025] Elapsed 3m 22s (remain 13m 51s) Loss: 0.8730(0.8545) Grad: 129167.0312  LR: 0.00001355  \n","Epoch: [2][300/1025] Elapsed 5m 3s (remain 12m 9s) Loss: 0.9282(0.8479) Grad: 130352.5469  LR: 0.00001314  \n","Epoch: [2][400/1025] Elapsed 6m 43s (remain 10m 28s) Loss: 0.7617(0.8460) Grad: 61473.9727  LR: 0.00001269  \n","Epoch: [2][500/1025] Elapsed 8m 24s (remain 8m 47s) Loss: 0.7417(0.8410) Grad: 64155.0664  LR: 0.00001219  \n","Epoch: [2][600/1025] Elapsed 10m 4s (remain 7m 6s) Loss: 0.7593(0.8368) Grad: 59774.8672  LR: 0.00001167  \n","Epoch: [2][700/1025] Elapsed 11m 45s (remain 5m 25s) Loss: 0.7300(0.8360) Grad: 57445.5234  LR: 0.00001111  \n","Epoch: [2][800/1025] Elapsed 13m 25s (remain 3m 45s) Loss: 0.7979(0.8344) Grad: 84825.7578  LR: 0.00001052  \n","Epoch: [2][900/1025] Elapsed 15m 5s (remain 2m 4s) Loss: 0.7393(0.8341) Grad: 46691.6719  LR: 0.00000991  \n","Epoch: [2][1000/1025] Elapsed 16m 46s (remain 0m 24s) Loss: 0.9541(0.8320) Grad: 287207.8125  LR: 0.00000928  \n","Epoch: [2][1024/1025] Elapsed 17m 10s (remain 0m 0s) Loss: 0.8384(0.8314) Grad: 188665.9375  LR: 0.00000913  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Score: 0.8582\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/1025] Elapsed 0m 1s (remain 23m 6s) Loss: 0.7544(0.7544) Grad: nan  LR: 0.00000913  \n","Epoch: [3][100/1025] Elapsed 1m 42s (remain 15m 35s) Loss: 0.7842(0.8117) Grad: 76645.1016  LR: 0.00000848  \n","Epoch: [3][200/1025] Elapsed 3m 22s (remain 13m 52s) Loss: 0.8486(0.8128) Grad: 84014.3438  LR: 0.00000783  \n","Epoch: [3][300/1025] Elapsed 5m 3s (remain 12m 9s) Loss: 0.7466(0.8117) Grad: 83059.7656  LR: 0.00000718  \n","Epoch: [3][400/1025] Elapsed 6m 43s (remain 10m 28s) Loss: 0.8584(0.8098) Grad: 102960.3594  LR: 0.00000653  \n","Epoch: [3][500/1025] Elapsed 8m 24s (remain 8m 47s) Loss: 0.7876(0.8103) Grad: 63566.7539  LR: 0.00000588  \n","Epoch: [3][600/1025] Elapsed 10m 4s (remain 7m 6s) Loss: 0.8335(0.8095) Grad: 200742.5000  LR: 0.00000525  \n","Epoch: [3][700/1025] Elapsed 11m 45s (remain 5m 25s) Loss: 0.7881(0.8089) Grad: 113522.0078  LR: 0.00000464  \n","Epoch: [3][800/1025] Elapsed 13m 25s (remain 3m 45s) Loss: 0.7876(0.8095) Grad: 139130.8594  LR: 0.00000404  \n","Epoch: [3][900/1025] Elapsed 15m 6s (remain 2m 4s) Loss: 0.8730(0.8096) Grad: 100418.6016  LR: 0.00000348  \n","Epoch: [3][1000/1025] Elapsed 16m 46s (remain 0m 24s) Loss: 0.8037(0.8094) Grad: 145487.0781  LR: 0.00000294  \n","Epoch: [3][1024/1025] Elapsed 17m 10s (remain 0m 0s) Loss: 0.7764(0.8088) Grad: 115858.7031  LR: 0.00000282  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Score: 0.8619\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/1025] Elapsed 0m 1s (remain 22m 33s) Loss: 0.7266(0.7266) Grad: nan  LR: 0.00000281  \n","Epoch: [4][100/1025] Elapsed 1m 42s (remain 15m 37s) Loss: 0.7803(0.7996) Grad: 112939.8984  LR: 0.00000232  \n","Epoch: [4][200/1025] Elapsed 3m 22s (remain 13m 51s) Loss: 0.6963(0.8006) Grad: 40083.8789  LR: 0.00000187  \n","Epoch: [4][300/1025] Elapsed 5m 3s (remain 12m 10s) Loss: 0.8032(0.7994) Grad: 86366.0781  LR: 0.00000146  \n","Epoch: [4][400/1025] Elapsed 6m 44s (remain 10m 28s) Loss: 0.7944(0.7994) Grad: 61073.1211  LR: 0.00000109  \n","Epoch: [4][500/1025] Elapsed 8m 24s (remain 8m 47s) Loss: 0.8193(0.8001) Grad: 90131.7891  LR: 0.00000078  \n","Epoch: [4][600/1025] Elapsed 10m 5s (remain 7m 6s) Loss: 0.8271(0.7992) Grad: 83382.3359  LR: 0.00000051  \n","Epoch: [4][700/1025] Elapsed 11m 45s (remain 5m 26s) Loss: 0.8789(0.7988) Grad: 144162.8438  LR: 0.00000030  \n","Epoch: [4][800/1025] Elapsed 13m 26s (remain 3m 45s) Loss: 0.9414(0.7999) Grad: 139780.7656  LR: 0.00000015  \n","Epoch: [4][900/1025] Elapsed 15m 6s (remain 2m 4s) Loss: 0.7651(0.8000) Grad: 63688.9961  LR: 0.00000005  \n","Epoch: [4][1000/1025] Elapsed 16m 46s (remain 0m 24s) Loss: 0.7681(0.8001) Grad: 88164.5234  LR: 0.00000000  \n","Epoch: [4][1024/1025] Elapsed 17m 11s (remain 0m 0s) Loss: 0.7349(0.8000) Grad: 73809.2422  LR: 0.00000000  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - Score: 0.8627\n","========== fold: 1 result ==========\n","Score: 0.8627\n","========== fold: 2 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1025] Elapsed 0m 2s (remain 49m 17s) Loss: 2.2461(2.2461) Grad: nan  LR: 0.00000003  \n","Epoch: [1][100/1025] Elapsed 1m 43s (remain 15m 47s) Loss: 1.2549(1.6082) Grad: 21878.0488  LR: 0.00000303  \n","Epoch: [1][200/1025] Elapsed 3m 24s (remain 13m 56s) Loss: 1.0957(1.3512) Grad: 17350.7402  LR: 0.00000603  \n","Epoch: [1][300/1025] Elapsed 5m 4s (remain 12m 12s) Loss: 0.8335(1.2389) Grad: 8387.5293  LR: 0.00000903  \n","Epoch: [1][400/1025] Elapsed 6m 45s (remain 10m 30s) Loss: 1.0234(1.1726) Grad: 16406.2207  LR: 0.00001203  \n","Epoch: [1][500/1025] Elapsed 8m 25s (remain 8m 48s) Loss: 0.8833(1.1233) Grad: 10794.3936  LR: 0.00001500  \n","Epoch: [1][600/1025] Elapsed 10m 6s (remain 7m 7s) Loss: 1.0391(1.0935) Grad: 12014.3291  LR: 0.00001497  \n","Epoch: [1][700/1025] Elapsed 11m 46s (remain 5m 26s) Loss: 0.8472(1.0695) Grad: 6795.7490  LR: 0.00001489  \n","Epoch: [1][800/1025] Elapsed 13m 27s (remain 3m 45s) Loss: 0.8398(1.0518) Grad: 7215.2500  LR: 0.00001474  \n","Epoch: [1][900/1025] Elapsed 15m 7s (remain 2m 4s) Loss: 0.9321(1.0369) Grad: 6254.3203  LR: 0.00001455  \n","Epoch: [1][1000/1025] Elapsed 16m 48s (remain 0m 24s) Loss: 0.9146(1.0244) Grad: 7775.6777  LR: 0.00001430  \n","Epoch: [1][1024/1025] Elapsed 17m 12s (remain 0m 0s) Loss: 1.0059(1.0219) Grad: 13694.8828  LR: 0.00001423  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Score: 0.8345\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/1025] Elapsed 0m 1s (remain 23m 2s) Loss: 0.8672(0.8672) Grad: nan  LR: 0.00001422  \n","Epoch: [2][100/1025] Elapsed 1m 43s (remain 15m 42s) Loss: 0.8003(0.8496) Grad: 141336.4375  LR: 0.00001391  \n","Epoch: [2][200/1025] Elapsed 3m 23s (remain 13m 54s) Loss: 0.8066(0.8451) Grad: 82424.3203  LR: 0.00001355  \n","Epoch: [2][300/1025] Elapsed 5m 4s (remain 12m 11s) Loss: 1.0156(0.8459) Grad: 160569.9531  LR: 0.00001314  \n","Epoch: [2][400/1025] Elapsed 6m 44s (remain 10m 29s) Loss: 0.8159(0.8434) Grad: 46629.4180  LR: 0.00001269  \n","Epoch: [2][500/1025] Elapsed 8m 25s (remain 8m 48s) Loss: 0.7788(0.8392) Grad: 49510.5117  LR: 0.00001219  \n","Epoch: [2][600/1025] Elapsed 10m 5s (remain 7m 7s) Loss: 0.7437(0.8378) Grad: 71466.1250  LR: 0.00001167  \n","Epoch: [2][700/1025] Elapsed 11m 46s (remain 5m 26s) Loss: 0.8091(0.8363) Grad: 37995.5352  LR: 0.00001111  \n","Epoch: [2][800/1025] Elapsed 13m 26s (remain 3m 45s) Loss: 0.8154(0.8371) Grad: 49694.4766  LR: 0.00001052  \n","Epoch: [2][900/1025] Elapsed 15m 7s (remain 2m 4s) Loss: 0.7754(0.8351) Grad: 33546.5430  LR: 0.00000991  \n","Epoch: [2][1000/1025] Elapsed 16m 47s (remain 0m 24s) Loss: 0.8916(0.8336) Grad: 68983.1875  LR: 0.00000928  \n","Epoch: [2][1024/1025] Elapsed 17m 11s (remain 0m 0s) Loss: 0.8311(0.8334) Grad: 45028.1523  LR: 0.00000913  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Score: 0.8489\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/1025] Elapsed 0m 1s (remain 22m 57s) Loss: 0.8516(0.8516) Grad: nan  LR: 0.00000913  \n","Epoch: [3][100/1025] Elapsed 1m 42s (remain 15m 37s) Loss: 0.7344(0.8172) Grad: 62778.0820  LR: 0.00000848  \n","Epoch: [3][200/1025] Elapsed 3m 23s (remain 13m 52s) Loss: 0.8174(0.8083) Grad: 74601.2422  LR: 0.00000783  \n","Epoch: [3][300/1025] Elapsed 5m 3s (remain 12m 10s) Loss: 0.9937(0.8068) Grad: 224918.9688  LR: 0.00000718  \n","Epoch: [3][400/1025] Elapsed 6m 44s (remain 10m 29s) Loss: 0.8354(0.8055) Grad: 140288.1094  LR: 0.00000653  \n","Epoch: [3][500/1025] Elapsed 8m 24s (remain 8m 48s) Loss: 0.8691(0.8061) Grad: 258899.5312  LR: 0.00000588  \n","Epoch: [3][600/1025] Elapsed 10m 5s (remain 7m 7s) Loss: 0.7188(0.8063) Grad: 49439.6836  LR: 0.00000525  \n","Epoch: [3][700/1025] Elapsed 11m 45s (remain 5m 26s) Loss: 0.7886(0.8061) Grad: 61491.5156  LR: 0.00000464  \n","Epoch: [3][800/1025] Elapsed 13m 26s (remain 3m 45s) Loss: 0.9062(0.8065) Grad: 240299.8594  LR: 0.00000404  \n","Epoch: [3][900/1025] Elapsed 15m 7s (remain 2m 4s) Loss: 0.8320(0.8064) Grad: 161554.5156  LR: 0.00000348  \n","Epoch: [3][1000/1025] Elapsed 16m 47s (remain 0m 24s) Loss: 0.7622(0.8067) Grad: 94936.3359  LR: 0.00000294  \n","Epoch: [3][1024/1025] Elapsed 17m 11s (remain 0m 0s) Loss: 0.7412(0.8068) Grad: 128084.0781  LR: 0.00000282  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Score: 0.8499\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/1025] Elapsed 0m 1s (remain 23m 21s) Loss: 0.8174(0.8174) Grad: nan  LR: 0.00000281  \n","Epoch: [4][100/1025] Elapsed 1m 42s (remain 15m 41s) Loss: 0.8779(0.7919) Grad: 121046.1719  LR: 0.00000232  \n","Epoch: [4][200/1025] Elapsed 3m 23s (remain 13m 54s) Loss: 0.7842(0.7949) Grad: 68046.0234  LR: 0.00000187  \n","Epoch: [4][300/1025] Elapsed 5m 3s (remain 12m 11s) Loss: 0.8760(0.7936) Grad: 78157.7734  LR: 0.00000146  \n","Epoch: [4][400/1025] Elapsed 6m 44s (remain 10m 29s) Loss: 0.8789(0.7951) Grad: 128813.5547  LR: 0.00000109  \n","Epoch: [4][500/1025] Elapsed 8m 25s (remain 8m 48s) Loss: 0.7710(0.7982) Grad: 90535.9844  LR: 0.00000078  \n","Epoch: [4][600/1025] Elapsed 10m 5s (remain 7m 7s) Loss: 0.8281(0.7979) Grad: 104382.9609  LR: 0.00000051  \n","Epoch: [4][700/1025] Elapsed 11m 46s (remain 5m 26s) Loss: 0.7949(0.7971) Grad: 121204.3359  LR: 0.00000030  \n","Epoch: [4][800/1025] Elapsed 13m 26s (remain 3m 45s) Loss: 0.8652(0.7969) Grad: 179202.4062  LR: 0.00000015  \n","Epoch: [4][900/1025] Elapsed 15m 7s (remain 2m 4s) Loss: 0.8140(0.7970) Grad: 94836.4375  LR: 0.00000005  \n","Epoch: [4][1000/1025] Elapsed 16m 47s (remain 0m 24s) Loss: 0.7881(0.7951) Grad: 174501.7344  LR: 0.00000000  \n","Epoch: [4][1024/1025] Elapsed 17m 12s (remain 0m 0s) Loss: 0.7158(0.7952) Grad: 105716.7656  LR: 0.00000000  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - Score: 0.8510\n","========== fold: 2 result ==========\n","Score: 0.8510\n","========== fold: 3 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1025] Elapsed 0m 2s (remain 38m 45s) Loss: 1.8975(1.8975) Grad: nan  LR: 0.00000003  \n","Epoch: [1][100/1025] Elapsed 1m 42s (remain 15m 41s) Loss: 1.6758(1.8022) Grad: 61454.3164  LR: 0.00000303  \n","Epoch: [1][200/1025] Elapsed 3m 23s (remain 13m 53s) Loss: 1.2090(1.6156) Grad: 35649.4414  LR: 0.00000603  \n","Epoch: [1][300/1025] Elapsed 5m 3s (remain 12m 10s) Loss: 0.9775(1.4384) Grad: 28906.3770  LR: 0.00000903  \n","Epoch: [1][400/1025] Elapsed 6m 44s (remain 10m 29s) Loss: 1.0244(1.3332) Grad: 33853.1719  LR: 0.00001203  \n","Epoch: [1][500/1025] Elapsed 8m 25s (remain 8m 48s) Loss: 0.9360(1.2631) Grad: 23728.2891  LR: 0.00001500  \n","Epoch: [1][600/1025] Elapsed 10m 5s (remain 7m 7s) Loss: 0.7861(1.2100) Grad: 21462.5391  LR: 0.00001497  \n","Epoch: [1][700/1025] Elapsed 11m 46s (remain 5m 26s) Loss: 1.0508(1.1726) Grad: 20854.9609  LR: 0.00001489  \n","Epoch: [1][800/1025] Elapsed 13m 26s (remain 3m 45s) Loss: 0.9067(1.1400) Grad: 15039.7480  LR: 0.00001474  \n","Epoch: [1][900/1025] Elapsed 15m 7s (remain 2m 4s) Loss: 1.0039(1.1153) Grad: 26018.0605  LR: 0.00001455  \n","Epoch: [1][1000/1025] Elapsed 16m 47s (remain 0m 24s) Loss: 0.8740(1.0950) Grad: 12814.3203  LR: 0.00001430  \n","Epoch: [1][1024/1025] Elapsed 17m 11s (remain 0m 0s) Loss: 0.9053(1.0907) Grad: 17948.9121  LR: 0.00001423  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Score: 0.8439\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/1025] Elapsed 0m 1s (remain 24m 49s) Loss: 0.8525(0.8525) Grad: nan  LR: 0.00001422  \n","Epoch: [2][100/1025] Elapsed 1m 42s (remain 15m 40s) Loss: 0.8247(0.8551) Grad: 103131.0234  LR: 0.00001391  \n","Epoch: [2][200/1025] Elapsed 3m 23s (remain 13m 53s) Loss: 0.7681(0.8487) Grad: 60655.6445  LR: 0.00001355  \n","Epoch: [2][300/1025] Elapsed 5m 4s (remain 12m 11s) Loss: 0.7690(0.8475) Grad: 39073.5195  LR: 0.00001314  \n","Epoch: [2][400/1025] Elapsed 6m 44s (remain 10m 29s) Loss: 0.7563(0.8416) Grad: 39478.4414  LR: 0.00001269  \n","Epoch: [2][500/1025] Elapsed 8m 25s (remain 8m 48s) Loss: 0.7363(0.8435) Grad: 35986.2969  LR: 0.00001219  \n","Epoch: [2][600/1025] Elapsed 10m 5s (remain 7m 7s) Loss: 0.9106(0.8418) Grad: 97659.4844  LR: 0.00001167  \n","Epoch: [2][700/1025] Elapsed 11m 46s (remain 5m 26s) Loss: 0.8691(0.8409) Grad: 81858.9531  LR: 0.00001111  \n","Epoch: [2][800/1025] Elapsed 13m 26s (remain 3m 45s) Loss: 0.8535(0.8398) Grad: 43414.9258  LR: 0.00001052  \n","Epoch: [2][900/1025] Elapsed 15m 7s (remain 2m 4s) Loss: 0.9004(0.8382) Grad: 97632.5000  LR: 0.00000991  \n","Epoch: [2][1000/1025] Elapsed 16m 47s (remain 0m 24s) Loss: 0.7798(0.8376) Grad: 39774.9766  LR: 0.00000928  \n","Epoch: [2][1024/1025] Elapsed 17m 11s (remain 0m 0s) Loss: 0.7993(0.8372) Grad: 47344.6094  LR: 0.00000913  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Score: 0.8599\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/1025] Elapsed 0m 1s (remain 22m 14s) Loss: 0.8081(0.8081) Grad: nan  LR: 0.00000913  \n","Epoch: [3][100/1025] Elapsed 1m 42s (remain 15m 36s) Loss: 0.8359(0.7986) Grad: 165367.1094  LR: 0.00000848  \n","Epoch: [3][200/1025] Elapsed 3m 22s (remain 13m 51s) Loss: 0.7153(0.7980) Grad: 67106.5859  LR: 0.00000783  \n","Epoch: [3][300/1025] Elapsed 5m 3s (remain 12m 10s) Loss: 0.9150(0.7967) Grad: 199091.2031  LR: 0.00000718  \n","Epoch: [3][400/1025] Elapsed 6m 44s (remain 10m 29s) Loss: 0.7559(0.7971) Grad: 69635.6875  LR: 0.00000653  \n","Epoch: [3][500/1025] Elapsed 8m 24s (remain 8m 47s) Loss: 0.8320(0.7978) Grad: 104149.5859  LR: 0.00000588  \n","Epoch: [3][600/1025] Elapsed 10m 5s (remain 7m 7s) Loss: 0.7817(0.7999) Grad: 81444.9375  LR: 0.00000525  \n","Epoch: [3][700/1025] Elapsed 11m 45s (remain 5m 26s) Loss: 0.8052(0.7986) Grad: 95124.6250  LR: 0.00000464  \n","Epoch: [3][800/1025] Elapsed 13m 26s (remain 3m 45s) Loss: 0.7324(0.7975) Grad: 82754.2266  LR: 0.00000404  \n","Epoch: [3][900/1025] Elapsed 15m 6s (remain 2m 4s) Loss: 0.7495(0.7979) Grad: 73034.8594  LR: 0.00000348  \n","Epoch: [3][1000/1025] Elapsed 16m 47s (remain 0m 24s) Loss: 0.7422(0.7975) Grad: 71914.0703  LR: 0.00000294  \n","Epoch: [3][1024/1025] Elapsed 17m 11s (remain 0m 0s) Loss: 0.7451(0.7972) Grad: 71732.7422  LR: 0.00000282  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Score: 0.8628\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/1025] Elapsed 0m 1s (remain 23m 24s) Loss: 0.7305(0.7305) Grad: nan  LR: 0.00000281  \n","Epoch: [4][100/1025] Elapsed 1m 42s (remain 15m 37s) Loss: 0.8311(0.7743) Grad: 236923.7500  LR: 0.00000232  \n","Epoch: [4][200/1025] Elapsed 3m 23s (remain 13m 52s) Loss: 0.8037(0.7777) Grad: 184535.7656  LR: 0.00000187  \n","Epoch: [4][300/1025] Elapsed 5m 3s (remain 12m 10s) Loss: 0.8032(0.7810) Grad: 86107.4453  LR: 0.00000146  \n","Epoch: [4][400/1025] Elapsed 6m 44s (remain 10m 28s) Loss: 0.8872(0.7834) Grad: 152214.2812  LR: 0.00000109  \n","Epoch: [4][500/1025] Elapsed 8m 24s (remain 8m 48s) Loss: 0.7544(0.7847) Grad: 99434.4453  LR: 0.00000078  \n","Epoch: [4][600/1025] Elapsed 10m 5s (remain 7m 7s) Loss: 0.8350(0.7844) Grad: 135982.3906  LR: 0.00000051  \n","Epoch: [4][700/1025] Elapsed 11m 45s (remain 5m 26s) Loss: 0.7314(0.7845) Grad: 32801.1484  LR: 0.00000030  \n","Epoch: [4][800/1025] Elapsed 13m 26s (remain 3m 45s) Loss: 0.7061(0.7841) Grad: 23101.6230  LR: 0.00000015  \n","Epoch: [4][900/1025] Elapsed 15m 6s (remain 2m 4s) Loss: 0.7944(0.7838) Grad: 52833.7812  LR: 0.00000005  \n","Epoch: [4][1000/1025] Elapsed 16m 47s (remain 0m 24s) Loss: 0.7563(0.7825) Grad: 41968.8320  LR: 0.00000000  \n","Epoch: [4][1024/1025] Elapsed 17m 11s (remain 0m 0s) Loss: 0.7881(0.7829) Grad: 71449.6562  LR: 0.00000000  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - Score: 0.8628\n","========== fold: 3 result ==========\n","Score: 0.8628\n","========== CV ==========\n","Score: 0.8618\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['score'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'/oof_df.pkl')\n","        \n","    if CFG.wandb:\n","        wandb.finish()"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"xAo-pYP_Q0eF","executionInfo":{"status":"ok","timestamp":1654463187768,"user_tz":-540,"elapsed":16,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"name":"exp019.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"388cc5bb0d4744d2b3bdc58bacdaa79b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7548e52829d45189a2669ffb65283d6","IPY_MODEL_c75e748d11f54696891ce1c02d0cd90d","IPY_MODEL_eb37b781e3894178b300efd102cccc4b"],"layout":"IPY_MODEL_3c1c2a8164eb459793880e74e9cff940"}},"d7548e52829d45189a2669ffb65283d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4709a2da3e784e9fa7916030c8a42591","placeholder":"​","style":"IPY_MODEL_34688dff697e4365875e00bf9f81898c","value":"Downloading: 100%"}},"c75e748d11f54696891ce1c02d0cd90d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e29da437a084a5695cde86a26bfd566","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9894e50a0574fb5a250b6ec5a727ea2","value":52}},"eb37b781e3894178b300efd102cccc4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95fdb51dc98c449ab92ba001a51bfd02","placeholder":"​","style":"IPY_MODEL_aba322c0d19548679e23ae05cacc38ca","value":" 52.0/52.0 [00:00&lt;00:00, 439B/s]"}},"3c1c2a8164eb459793880e74e9cff940":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4709a2da3e784e9fa7916030c8a42591":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34688dff697e4365875e00bf9f81898c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e29da437a084a5695cde86a26bfd566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9894e50a0574fb5a250b6ec5a727ea2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95fdb51dc98c449ab92ba001a51bfd02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aba322c0d19548679e23ae05cacc38ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efebe0e47c284509a961cd3a2b8a425a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b44e84feaaa48b89083b86e4dceaaee","IPY_MODEL_c75302f1bf9b493cb380368c8c350f77","IPY_MODEL_127bc45e8c4f4ccb8ff1918d39749439"],"layout":"IPY_MODEL_e85de0dd0ae1470ebacb398c6a400987"}},"0b44e84feaaa48b89083b86e4dceaaee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2386f21bc9f42e3a2ba37abef6d171c","placeholder":"​","style":"IPY_MODEL_3fc343960ea74699b5d36b944a215336","value":"Downloading: 100%"}},"c75302f1bf9b493cb380368c8c350f77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f29759c12b849aa8adb1c11a1fb1e92","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f171e5f46bc84b2ea533e5705ad519d0","value":580}},"127bc45e8c4f4ccb8ff1918d39749439":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0a036f4da2b439abd66d338e15d1df6","placeholder":"​","style":"IPY_MODEL_8e28220377fc405ea82febb190425d61","value":" 580/580 [00:00&lt;00:00, 6.68kB/s]"}},"e85de0dd0ae1470ebacb398c6a400987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2386f21bc9f42e3a2ba37abef6d171c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fc343960ea74699b5d36b944a215336":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f29759c12b849aa8adb1c11a1fb1e92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f171e5f46bc84b2ea533e5705ad519d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0a036f4da2b439abd66d338e15d1df6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e28220377fc405ea82febb190425d61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2ae7ed3c7694024b6f8697982324391":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1b20f06653b48018be12077706fe0ad","IPY_MODEL_0d1a2b4a47d547f298c99f731d0d4fc7","IPY_MODEL_fd0adb1ee69b4fb287572cd12d2b7162"],"layout":"IPY_MODEL_95be8e0c3992451bbf698c668fb5cc89"}},"e1b20f06653b48018be12077706fe0ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3f8ea70e64e46c5b36587b35970b52c","placeholder":"​","style":"IPY_MODEL_d627f4dede75400aabae4c5bfb610b12","value":"Downloading: 100%"}},"0d1a2b4a47d547f298c99f731d0d4fc7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7db990dcd612470789f4b56793ee4b29","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c8464542d904436a0fd5add7fa51fae","value":2464616}},"fd0adb1ee69b4fb287572cd12d2b7162":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e10c0f2aa8047e4bbd33c3dfc5df4a3","placeholder":"​","style":"IPY_MODEL_c20396bc7d844d00b0eafec48c9c316a","value":" 2.35M/2.35M [00:00&lt;00:00, 6.41MB/s]"}},"95be8e0c3992451bbf698c668fb5cc89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3f8ea70e64e46c5b36587b35970b52c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d627f4dede75400aabae4c5bfb610b12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7db990dcd612470789f4b56793ee4b29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c8464542d904436a0fd5add7fa51fae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e10c0f2aa8047e4bbd33c3dfc5df4a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c20396bc7d844d00b0eafec48c9c316a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58045be8708147ccad087ea96543fc63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29291a37050b4e149e4d31d3b86c798b","IPY_MODEL_5e3cfa7f20aa4d27a5b8b58f2a63aecb","IPY_MODEL_084b90ae4d074f7a81d5b9868b0d01f0"],"layout":"IPY_MODEL_edd12735f0254c77a377bb762e584ca2"}},"29291a37050b4e149e4d31d3b86c798b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6ea6447019844dc99f93f88ce0e4a0b","placeholder":"​","style":"IPY_MODEL_7cfa1f4a74884c73a7a367b993da3162","value":"100%"}},"5e3cfa7f20aa4d27a5b8b58f2a63aecb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a199c0fdf524a99b0d420430fbb642d","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b0c3ee129724000b582ad4d79704eee","value":36473}},"084b90ae4d074f7a81d5b9868b0d01f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a246a817907421d9476cd81d88fa0b5","placeholder":"​","style":"IPY_MODEL_dd7b9212a065445697ba1cd333dd6d64","value":" 36473/36473 [00:06&lt;00:00, 3767.99it/s]"}},"edd12735f0254c77a377bb762e584ca2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6ea6447019844dc99f93f88ce0e4a0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cfa1f4a74884c73a7a367b993da3162":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a199c0fdf524a99b0d420430fbb642d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b0c3ee129724000b582ad4d79704eee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a246a817907421d9476cd81d88fa0b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd7b9212a065445697ba1cd333dd6d64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6de33cc1c0634eed96693db8d5c7634e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67787fd8acf74c0bae0ccdc5f3e6b1e9","IPY_MODEL_e64cec66571c4e56b17d0ee2fe2f9f51","IPY_MODEL_29708ec2a2d7493d9bbc08cdc31e8f46"],"layout":"IPY_MODEL_3c63df8931da4bb6a5f35600825f0e82"}},"67787fd8acf74c0bae0ccdc5f3e6b1e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1cac53be3584725bb6d4716a12fafb8","placeholder":"​","style":"IPY_MODEL_182ff7ab057245128956b2ea65e910df","value":"100%"}},"e64cec66571c4e56b17d0ee2fe2f9f51":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c664034e29e341a6a169f9c1586c08e9","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85cae7be4aae495694a0fe3ae4a3ff95","value":36473}},"29708ec2a2d7493d9bbc08cdc31e8f46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4b050c1044d45aa87899d7f5335f3bd","placeholder":"​","style":"IPY_MODEL_25d1131fa6964471809a73923b1af45f","value":" 36473/36473 [00:10&lt;00:00, 3506.45it/s]"}},"3c63df8931da4bb6a5f35600825f0e82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1cac53be3584725bb6d4716a12fafb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"182ff7ab057245128956b2ea65e910df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c664034e29e341a6a169f9c1586c08e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85cae7be4aae495694a0fe3ae4a3ff95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4b050c1044d45aa87899d7f5335f3bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25d1131fa6964471809a73923b1af45f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"972ea9d4061c4e5cb2042312b98a771a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_734df4ac8ed947df9606c8a961096164","IPY_MODEL_c873bdb7217e417ab118bbfbb79c990a","IPY_MODEL_2d99eba6bbe54240af5e37daf03d503a"],"layout":"IPY_MODEL_54ac6a1c01ff4ce6a3426067f0073bca"}},"734df4ac8ed947df9606c8a961096164":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea8e48675abd44899ca708968dd91356","placeholder":"​","style":"IPY_MODEL_2f0fd9f0c67441279dba32068dc2f955","value":"100%"}},"c873bdb7217e417ab118bbfbb79c990a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b9aeeb1a5794964bd2e89ae50ffbe8a","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1906b2f85d94ef4888196cc6ebf30d0","value":36473}},"2d99eba6bbe54240af5e37daf03d503a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_932843b6af8447d5b883f7477a8b8fa9","placeholder":"​","style":"IPY_MODEL_56e628ddcccf4b77b4501f9ee1756a10","value":" 36473/36473 [00:11&lt;00:00, 4022.47it/s]"}},"54ac6a1c01ff4ce6a3426067f0073bca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea8e48675abd44899ca708968dd91356":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f0fd9f0c67441279dba32068dc2f955":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b9aeeb1a5794964bd2e89ae50ffbe8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1906b2f85d94ef4888196cc6ebf30d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"932843b6af8447d5b883f7477a8b8fa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56e628ddcccf4b77b4501f9ee1756a10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a13ac523446b49feaabd97f0827918d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30dfc6a1d3174e7dacb42b67e16f630c","IPY_MODEL_2da9f7d6ff174b6da557d53a0fa4c393","IPY_MODEL_b06ca09cac1047babbe14495d00441ee"],"layout":"IPY_MODEL_07411170b52643978bc9fd4b7da11fba"}},"30dfc6a1d3174e7dacb42b67e16f630c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47dc8bbcc4b443a697b21d38480951cf","placeholder":"​","style":"IPY_MODEL_6078240c0d7f4feaa000f91260dda579","value":"100%"}},"2da9f7d6ff174b6da557d53a0fa4c393":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97e8ffc0de8c4a3e88136aa8a2cbca34","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a762a66f7f542e197d4a8b700877a19","value":36473}},"b06ca09cac1047babbe14495d00441ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f481e09252564143bb1ca5a804117fc8","placeholder":"​","style":"IPY_MODEL_28972586d7794c5db54feb5ae98f77ba","value":" 36473/36473 [00:07&lt;00:00, 7848.58it/s]"}},"07411170b52643978bc9fd4b7da11fba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47dc8bbcc4b443a697b21d38480951cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6078240c0d7f4feaa000f91260dda579":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97e8ffc0de8c4a3e88136aa8a2cbca34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a762a66f7f542e197d4a8b700877a19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f481e09252564143bb1ca5a804117fc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28972586d7794c5db54feb5ae98f77ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"373615ca39dc49ea84ba10916caf03d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6508314fe7b045cf805287982ffef5b2","IPY_MODEL_d320153c927b484683c940c60ed1ab9e","IPY_MODEL_daa46be7d90c4dada74093dbb5b1b126"],"layout":"IPY_MODEL_76ade73eddda433e8ca10fc17562ab81"}},"6508314fe7b045cf805287982ffef5b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9600ad091a5b41cba70300c646c2be94","placeholder":"​","style":"IPY_MODEL_a7cb223076e9495eb35736168fa5ff17","value":"Downloading: 100%"}},"d320153c927b484683c940c60ed1ab9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a6674747b6c46e596d2d0e4645ef51e","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6aa2ea76437e422cb3ab1e4a6287d3b0","value":873673253}},"daa46be7d90c4dada74093dbb5b1b126":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f8bbd195e2a4939a5509c43b861207b","placeholder":"​","style":"IPY_MODEL_0a03cd32416e4e2396cf0d25d0584b2c","value":" 833M/833M [00:42&lt;00:00, 40.6MB/s]"}},"76ade73eddda433e8ca10fc17562ab81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9600ad091a5b41cba70300c646c2be94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7cb223076e9495eb35736168fa5ff17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a6674747b6c46e596d2d0e4645ef51e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6aa2ea76437e422cb3ab1e4a6287d3b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f8bbd195e2a4939a5509c43b861207b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a03cd32416e4e2396cf0d25d0584b2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}