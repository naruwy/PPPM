{"cells":[{"cell_type":"markdown","metadata":{"id":"e460cbb5"},"source":["# About this notebook\n","- Deberta-v3-large starter code\n","- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/pppm-pip-wheels)\n","- Inference notebook is [here](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n","\n","If this notebook is helpful, feel free to upvote :)"]},{"cell_type":"markdown","metadata":{"id":"LY7ihXf3QHH4"},"source":["### embedを得るためのnote"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":375,"status":"ok","timestamp":1654587339118,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"VmlmoWLINmmv","outputId":"7da4149b-4848-4477-8c44-8e191328fd75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Jun  7 07:35:36 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"zULc94aSNyF4"},"source":["# Directory settings"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654587339119,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"fa3b873b"},"outputs":[],"source":["# ====================================================\n","# Directory settings\n","# ====================================================\n","import os\n","import sys\n","import json\n","# INPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\n","# OUTPUT_DIR = './'\n","# if not os.path.exists(OUTPUT_DIR):\n","#     os.makedirs(OUTPUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"1d0c4430"},"source":["# CFG"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654587339119,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"48dd82bb"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    wandb=False\n","    competition='PPPM'\n","    _wandb_kernel='nakama'\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-large\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=500\n","    epochs=4\n","    encoder_lr=1.5e-5\n","    decoder_lr=15e-5 # decoder_lrを10倍してみる\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.0\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    newtrain = True\n","\n","    name = \"exp018c\" # 実験のたびにコピーしてここの名前を変えて実行するとoutputが別のファイルに保存される\n","    api_path = \"/content/drive/MyDrive/kaggle/kaggle.json\"\n","    drive_path = \"/content/drive/MyDrive/kaggle/PPPM\"\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654587339119,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"RuhtrhPoOPiA"},"outputs":[],"source":["COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4396,"status":"ok","timestamp":1654587343512,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"2e07M6l6OOE3","outputId":"190ea30b-a94c-4b53-f3e1-b803bbe049a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kaggle\n","  Downloading kaggle-1.5.12.tar.gz (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 2.5 MB/s \n","\u001b[?25hBuilding wheels for collected packages: kaggle\n","  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=f6146173715829a356461ceeb017f9334eade20634b196713e594765ac3a0587\n","  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n","Successfully built kaggle\n","Installing collected packages: kaggle\n","  Attempting uninstall: kaggle\n","    Found existing installation: kaggle 1.5.12\n","    Uninstalling kaggle-1.5.12:\n","      Successfully uninstalled kaggle-1.5.12\n","Successfully installed kaggle-1.5.12\n"]}],"source":["!pip install --upgrade --force-reinstall --no-deps kaggle"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19372,"status":"ok","timestamp":1654587362878,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"fjK0B5nGOjSB","outputId":"dd3e90a3-b1de-4bee-b33e-c0dd51d8541b"},"outputs":[{"output_type":"stream","name":"stdout","text":["This environment is Google Colab\n","Mounted at /content/drive\n"]}],"source":["if COLAB:\n","    print(\"This environment is Google Colab\")\n","    \n","    # mount\n","    from google.colab import drive\n","    if not os.path.isdir(\"/content/drive\"):\n","        drive.mount('/content/drive') \n","\t\n","    \n","    # use kaggle api (need kaggle token)\n","    f = open(CFG.api_path, 'r')\n","    json_data = json.load(f) \n","    os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","    os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n","    \n","    # set dirs\n","    DRIVE = CFG.drive_path\n","    EXP = CFG.name\n","    INPUT_DIR = os.path.join(DRIVE, \"Input\")\n","    OUTPUT_DIR = os.path.join(DRIVE, \"Output\")\n","    SCRIPT = os.path.join(DRIVE, \"Script\")\n","    OUTPUT_DIR = os.path.join(OUTPUT_DIR, EXP) \n","    # EXP_MODEL = os.path.join(OUTPUT_EXP, \"model\")\n","    # EXP_FIG = os.path.join(OUTPUT_EXP, \"fig\")\n","    # EXP_PREDS = os.path.join(OUTPUT_EXP, \"preds\")\n","\n","    # make dirs\n","    for d in [INPUT_DIR, SCRIPT, OUTPUT_DIR]:\n","        os.makedirs(d, exist_ok=True)\n","\n","    if not os.path.isfile(os.path.join(INPUT_DIR, \"us-patent-phrase-to-phrase-matching.zip\")):\n","        # load dataset\n","        ! kaggle competitions download -c us-patent-phrase-to-phrase-matching -p $INPUT_DIR \n","        unzip_file = os.path.join(INPUT_DIR, 'us-patent-phrase-to-phrase-matching.zip')\n","        ! unzip $unzip_file -d $INPUT_DIR\n","    \n","    if not os.path.isfile(os.path.join(INPUT_DIR, \"cpc-data.zip\")):\n","        # load dataset\n","        ! kaggle datasets download -d yasufuminakama/cpc-data -p $INPUT_DIR\n","        unzip_file = os.path.join(INPUT_DIR, 'cpc-data.zip')\n","        ! unzip $unzip_file -d $INPUT_DIR\n","\n","else:\n","    print(\"This environment is Kaggle Kernel\")\n","    \n","    # set dirs\n","    INPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\n","    OUTPUT_DIR = './'\n","    \n","    \n","    # # copy dirs\n","    # if Config.kaggle_dataset_path is not None:\n","    #     KD_MODEL = os.path.join(Config.kaggle_dataset_path, \"model\")\n","    #     KD_EXP_PREDS = os.path.join(Config.kaggle_dataset_path, \"preds\")\n","    #     shutil.copytree(KD_MODEL, EXP_MODEL)\n","    #     shutil.copytree(KD_EXP_PREDS, EXP_PREDS)\n","\n","    # # make dirs\n","    # for d in [EXP_MODEL, EXP_FIG, EXP_PREDS]:\n","    #     os.makedirs(d, exist_ok=True)\n","        \n","    "]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1654587362879,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"b88c983e"},"outputs":[],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    \n","    import wandb\n","\n","    try:\n","        from kaggle_secrets import UserSecretsClient\n","        user_secrets = UserSecretsClient()\n","        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        wandb.login(key=secret_value_0)\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project='PPPM-Public', \n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=CFG.model,\n","                     job_type=\"train\",\n","                     anonymous=anony)"]},{"cell_type":"markdown","metadata":{"id":"f2ed8ef2"},"source":["# Library"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28745,"status":"ok","timestamp":1654587391620,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"35916341","outputId":"a980e1f0-8ded-403d-c507-55e0e5cb112b"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.__version__: 1.11.0+cu113\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers[sentencepiece]\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.7.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 2.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.11.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 41.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 46.3 MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 49.2 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.8.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, sentencepiece\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.19.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers==0.12.1 in /usr/local/lib/python3.7/dist-packages (0.12.1)\n","tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.19.2\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, StratifiedGroupKFold\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","# !pip install transformers==4.18.0\n","!pip install transformers[sentencepiece]\n","!pip install tokenizers==0.12.1\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","import lightgbm as lgb\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"fd586614"},"source":["# Utils"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1654587391621,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"d5c0ccc6"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = sp.stats.pearsonr(y_true, y_pred)[0]\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'/train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"cb3d8e1e"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":732,"status":"ok","timestamp":1654587392342,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"bef012d3"},"outputs":[],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv(INPUT_DIR+'/train.csv')\n","test = pd.read_csv(INPUT_DIR+'/test.csv')\n","submission = pd.read_csv(INPUT_DIR+'/sample_submission.csv')\n","# print(f\"train.shape: {train.shape}\")\n","# print(f\"test.shape: {test.shape}\")\n","# print(f\"submission.shape: {submission.shape}\")\n","# display(train.head())\n","# display(test.head())\n","# display(submission.head())"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"elapsed":4140,"status":"ok","timestamp":1654587396481,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"AqzuRHB_NyGF","outputId":"c829fff6-7688-4335-f830-e5c7d9672f70"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                 id     anchor                  target context  score                                       context_text\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."],"text/html":["\n","  <div id=\"df-deaa1a0e-e396-40b6-a475-05f204413564\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-deaa1a0e-e396-40b6-a475-05f204413564')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-deaa1a0e-e396-40b6-a475-05f204413564 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-deaa1a0e-e396-40b6-a475-05f204413564');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                 id              anchor                         target context                                       context_text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"],"text/html":["\n","  <div id=\"df-ec7d065c-4ddc-450d-b2a2-ea2585b7c03a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>opc drum</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","      <td>PHYSICS. OPTICS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>adjust gas flow</td>\n","      <td>altering gas flow</td>\n","      <td>F23</td>\n","      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>lower trunnion</td>\n","      <td>lower locating</td>\n","      <td>B60</td>\n","      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>cap component</td>\n","      <td>upper portion</td>\n","      <td>D06</td>\n","      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>neural stimulation</td>\n","      <td>artificial neural network</td>\n","      <td>H04</td>\n","      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec7d065c-4ddc-450d-b2a2-ea2585b7c03a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ec7d065c-4ddc-450d-b2a2-ea2585b7c03a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ec7d065c-4ddc-450d-b2a2-ea2585b7c03a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["# ====================================================\n","# CPC Data\n","# ====================================================\n","def get_cpc_texts():\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    if COLAB:\n","        cpcpath = os.path.join(INPUT_DIR, 'CPCSchemeXML202105')\n","    else:\n","        cpcpath = '../input/cpc-data/CPCSchemeXML202105'\n","    for file_name in os.listdir(cpcpath):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        if COLAB:\n","            cpcpath = os.path.join(INPUT_DIR, f'CPCTitleList202202/cpc-section-{cpc}_20220201.txt')\n","        else:\n","            cpcpath = f'../input/cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt'\n","        with open(cpcpath) as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    return results\n","\n","\n","cpc_texts = get_cpc_texts()\n","torch.save(cpc_texts, OUTPUT_DIR+\"/cpc_texts.pth\")\n","train['context_text'] = train['context'].map(cpc_texts)\n","test['context_text'] = test['context'].map(cpc_texts)\n","display(train.head())\n","display(test.head())"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1654587396482,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"uSqmGITONyGG"},"outputs":[],"source":["train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n","test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n","# display(train.head())\n","# display(test.head())"]},{"cell_type":"markdown","metadata":{"id":"uYPq-UFTNyGH"},"source":["# EDA"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1654587396483,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"wcCwUv5eNyGH"},"outputs":[],"source":["# train['score'].hist()"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1654587396484,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"vob-KqQINyGH"},"outputs":[],"source":["# display(train['context'].apply(lambda x: x[0]).value_counts())"]},{"cell_type":"markdown","metadata":{"id":"VJIOGLybNyGI"},"source":["- Y is not in training data, but may be in test data?"]},{"cell_type":"markdown","metadata":{"id":"9e05b6c4"},"source":["# CV split"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1654587396485,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"4ZMUtDpFO5K8"},"outputs":[],"source":["# # ====================================================\n","# # CV split\n","# # ====================================================\n","# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","# Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n","#     train.loc[val_index, 'fold'] = int(n)\n","# train['fold'] = train['fold'].astype(int)\n","# display(train.groupby('fold').size())"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2077,"status":"ok","timestamp":1654587398545,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"TB-cGGuQ-Qi9","colab":{"base_uri":"https://localhost:8080/","height":233},"outputId":"141abdb1-9c31-48fc-eae1-33871a450e65"},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    3560\n","1    3994\n","2    3501\n","3    3691\n","4    3786\n","5    3582\n","6    3489\n","7    4030\n","8    3323\n","9    3517\n","dtype: int64"]},"metadata":{}}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","Fold = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'], train['anchor'])):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654587398546,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"4c3ce877"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"918a28aa"},"source":["# tokenizer"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["3d24769f94164c998ccd05b3c5c5073c","9536eb8c39364c20ab1c12e55828d451","38b6460a6b814b8189ef78e39422b1f9","6d19bc209fdb4c059e93beca744181c4","66c8cd20f2c64dedb83a0e8e38d64c4c","4cd81607514f4314824e7e26ef79d3b4","421ea233ec2a4f27ba179b5ca5090166","a3b1361bd284435fb098ec0a193e50fc","e4cf8ea7e2dc45f99dfad6d1e85c5d83","d47bdfabcea3491caa2fd7ced1b2c2bf","c51231f290dc44dbb3bf9e457ded838c","80f3e1ee8fac49eeb7e229b85774957c","c17733f7d6b144f19e9fcdefcd04d48e","cea9aafb791c47eaa815232ce54416f8","f44b5813c4824dfc8db016230bfd0039","c7cd83ac7d3342f3bde12c628d861269","e6b0254336a242619bc58e649ff4ec45","5ebe58537b084831818cb05d20879bde","3a318a462bea4ef6b320e343b69d0961","89329d9483424bf0add62c5402224e51","c2228812f1214b16a91365417e077cfe","89376cc47dca48a1843252c74f7aaa17","42973ce7d913440e9d9d25b2ebda96b0","cb0aae3f1a634be3b84518f78d80581d","178a24e11fd04591bde8b091e05b08fd","3683189ae96d45aeab9f22e9740a3b99","57648f3f9e664e5186ca12c3b7615b76","3b592d44790d447b833db49f13336a25","f329410721754354b2a3e01c97a27588","49a4dde53e2d4b73b5883dbb3eb04fe3","8c619abb8c90401fab3d1547f88e435a","371f7d3c97f8494ebb94383eec217465","a64a734a3b2b4e2a8d068b97c8a53100"]},"executionInfo":{"elapsed":14181,"status":"ok","timestamp":1654587412723,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"KCSjp89kNyGJ","outputId":"c90576bc-73ea-455a-ca00-5d4b8b89fb14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d24769f94164c998ccd05b3c5c5073c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80f3e1ee8fac49eeb7e229b85774957c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42973ce7d913440e9d9d25b2ebda96b0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","! pip install sentencepiece\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'/tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"14da40cf"},"source":["# Dataset"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["0ba883d90f7049eca9dbb06ad16da049","8148f22c19aa4829aa94f7e415378ec4","d452c386bd764c2ea96a000a665c633d","53ddedb0630945ad92d8474d643bf236","e909d4de67b34d20a25f97b87fa75452","ae4e5d1bba1945d99e9e087450ec2e60","b267a022c9be4f84851bdc30469e3c15","50f442e64bb047e9a2d68fa657d59a46","87e3b1b1696e416e8a5acac6b5c234e4","71df11cce24e4c42b005e96b2dd87dc6","3b89e9d29f5f4104af812c81f0a25c8e","31fc542ccd634eada5caa460fcb0ceeb","552ea2bb18994288963f26c9a5115730","491681ddb5ce4fb998663910c0e55e4f","5d8d73bcea8d48d1846a1352fde52253","125b0bea10b142dc97427e52a52fe304","573f5a13e7ec4b3d9c73dc02c299731a","08a1d8b6599b4a699073653cfec0b78c","274884040edc4a90865dbb2b9a789887","5fa66957017b4f6a9ff134cd2d5b82cb","788aa14f1e8e44b082a06cca0d99de15","32d3ba3ec7eb4559835a0a6c5e8df0ba","d138a7fa018c4fdf80962c5f16f4191e","6e0d75e1003d4938bd977cb48e43cbe3","48a5f1a3f4994021af7317db87331337","7327d51b28e04ea4acc603789a516f89","eb6679f5a9004591a5bf537a84df6403","aa4b05568429416386dd7e4d27b1b193","2ecf01462d044fc0a2811b0dc3203dde","ffece297e020461a952222d0c0e84bdb","698b4423afd64dae8f30b2d1930d785b","9a7def68913141ec83d7e24c6d80b3a8","424707f246214c8faed3e7048b4b9c0d"]},"executionInfo":{"elapsed":14516,"status":"ok","timestamp":1654587427226,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"c00327b0","outputId":"a7119f62-b51f-4dab-9e53-5fad17ceeb66"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/136 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ba883d90f7049eca9dbb06ad16da049"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/36473 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31fc542ccd634eada5caa460fcb0ceeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/36473 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d138a7fa018c4fdf80962c5f16f4191e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_len: 133\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths_dict = {}\n","\n","lengths = []\n","tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","lengths_dict['context_text'] = lengths\n","\n","for text_col in ['anchor', 'target']:\n","    lengths = []\n","    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        lengths.append(length)\n","    lengths_dict[text_col] = lengths\n","    \n","CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n","                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1654587427227,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"9f791a19"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1654587427227,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"a200bd5b","outputId":"108886bd-ec4e-4eef-dd34-673eb2fb2879"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntrain_dataset = TrainDataset(CFG, train)\\ninputs, label = train_dataset[0]\\nprint(inputs)\\nprint(label)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}],"source":["\"\"\"\n","train_dataset = TrainDataset(CFG, train)\n","inputs, label = train_dataset[0]\n","print(inputs)\n","print(label)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"e04d6363"},"source":["# Model"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1654587427228,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"2mLyXDgoHwmQ"},"outputs":[],"source":["class TransformerHead(nn.Module):\n","    def __init__(self, in_features, max_length, num_layers=1, nhead=8, num_targets=1):\n","        super().__init__()\n","        # in_features は各トークンに対するベクトルの次元数\n","        # max_length は最大トークン数\n","        self.transformer = nn.TransformerEncoder(encoder_layer=nn.TransformerEncoderLayer(d_model=in_features,\n","                                                                                          nhead=nhead),\n","                                                 num_layers=num_layers)\n","        self.row_fc = nn.Linear(in_features, 1)\n","        self.out_features = max_length\n","\n","    def forward(self, x):\n","        out = self.transformer(x)\n","        out = self.row_fc(out).squeeze(-1)\n","        return out"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1654587427228,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"4c5bab44"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        \n","        in_features = self.config.hidden_size\n","        self.attention = TransformerHead(in_features=in_features, max_length=cfg.max_len, num_layers=1, nhead=8, num_targets=1)\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.attention.out_features, self.cfg.target_size)\n","        self._init_weights(self.fc)\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        # feature = torch.mean(last_hidden_states, 1)\n","        feature = self.attention(last_hidden_states)\n","        \n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","#         print(feature.shape)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output, feature"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1654587427228,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"Q6jysiLTMiUN"},"outputs":[],"source":["class Pearson_Loss(nn.Module):\n","    def __init__(self):\n","        super(Pearson_Loss, self).__init__()\n","\n","    def forward(self, label, preds):\n","        preds_mean = torch.mean(preds)\n","        label_mean = torch.mean(label)\n","\n","        num = torch.sum(torch.mul((preds-preds_mean),(label-label_mean)))\n","\n","        pred_std = torch.sum(torch.square((preds-preds_mean)))\n","        label_std = torch.sum(torch.square((label-label_mean)))\n","        den = torch.sqrt(pred_std * label_std)\n","        loss = 1-torch.divide(num, den)\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"deee9675"},"source":["# Helpler functions"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":840,"status":"ok","timestamp":1654587428057,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"c8263b0c"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterions, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds, _ = model(inputs)\n","        # loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        loss = None\n","        for criterion in criterions:\n","            if loss == None:\n","                loss = criterion(y_preds.view(-1, 1).to(torch.half), labels.view(-1, 1).to(torch.half))\n","            else:\n","                loss += criterion(y_preds.view(-1, 1).to(torch.half), labels.view(-1, 1).to(torch.half))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterions, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds, _ = model(inputs)\n","        # loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        loss = None\n","        for criterion in criterions:\n","            if loss == None:\n","                loss = criterion(y_preds.view(-1, 1).to(torch.half), labels.view(-1, 1).to(torch.half))\n","            else:\n","                loss += criterion(y_preds.view(-1, 1).to(torch.half), labels.view(-1, 1).to(torch.half))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds, _ = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":407,"status":"ok","timestamp":1654587428458,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"ovXqVJlFLdMj"},"outputs":[],"source":["### lightgbm\n","### 適当なやつ\n","def train_fn_(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    from lightgbm import LGBMRegressor\n","    model.eval()\n","\n","    embeds = []\n","    targets = []\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        with torch.no_grad():\n","            y_preds, embed = model(inputs)\n","        embeds.append(embed.to('cpu').numpy())\n","        targets.append(labels.to('cpu').numpy())\n","    embeds = np.concatenate(embeds) # (datasize, 768)\n","    targets = np.concatenate(targets) # (datasize, 1)\n","    \n","    params = {\n","    'objective': 'regression',\n","    'boosting_type': 'gbdt',  # default = 'gbdt'\n","    'num_leaves': 2**8-1, #63,         # default = 31,\n","    'learning_rate': 0.01,    # default = 0.1\n","    'feature_fraction': 0.8,  # default = 1.0\n","    'bagging_freq': 1,        # default = 0\n","    'bagging_fraction': 0.8,  # default = 1.0\n","    'random_state': 0,        # default = None\n","    'max_depth': 8,\n","#     'min_data_in_leaf': 50,   # default = 20\n","    'verbosity': -1,\n","}\n","    \n","\n","    train_data = lgb.Dataset(\n","        data=embeds, \n","        label=targets, \n","    )\n","\n","    bst = lgb.train(params=params, \n","                    train_set=train_data, \n","                    num_boost_round=600)\n","\n","    return bst, embeds, targets\n","\n","def valid_fn_(valid_loader, model, criterion, device, gbdt):\n","    model.eval()\n","    preds = []\n","    embeds = []\n","    targets = []\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        with torch.no_grad():\n","            _, embed = model(inputs)\n","        embeds.append(embed.to('cpu').numpy())\n","        targets.append(labels.to('cpu').numpy())\n","\n","        y_preds = gbdt.predict(embed.to('cpu').numpy())\n","        preds.append(y_preds)\n","\n","    predictions = np.concatenate(preds)\n","    embeds = np.concatenate(embeds) # (datasize, 768)\n","    targets = np.concatenate(targets) # (datasize, 1)\n","#     predictions = np.concatenate(predictions)\n","    return predictions, embeds, targets\n","\n","\n","# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['score'].values\n","\n","    # newtrain ============================================\n","    if CFG.newtrain:\n","        path = os.path.join(INPUT_DIR, 'newtrain.csv')\n","        df = pd.read_csv(path)\n","        r = [0.95, 0.97, 0.7, 0.60, 0.98]\n","        m = ['0', '1', '2', '3', '4']\n","        new_df = []\n","        for i, j in zip(m, r):\n","            idx = df[i] > j\n","            df.loc[idx, 'score'] = int(i) * 0.25\n","            new_df.append(df[idx])\n","        new_train = pd.concat(new_df)\n","        train_folds = pd.concat([train_folds[['text', 'score']], new_train[['text', 'score']]])\n","    # ======================================================\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    model.config.update(\n","        {\n","            \"attention_probs_dropout_prob\" : 0.0,\n","            \"hidden_dropout_prob\": 0.0\n","        }\n","    )\n","    torch.save(model.config, OUTPUT_DIR+'/config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = [nn.BCEWithLogitsLoss(reduction=\"mean\"), nn.MSELoss(reduction='mean'), Pearson_Loss()]\n","    \n","    best_score = 0.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","        \n","        # lightgbm train\n","        gbdt, embeds_tr, targets_tr = train_fn_(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        predictions, embeds_va, targets_va = valid_fn_(valid_loader, model, criterion, device, gbdt)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","#         LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if best_score < score:\n","            best_score = score\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","            gbdt.save_model(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_best_gbdt.txt\")\n","        \n","            np.save(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_embeds_tr\", embeds_tr)\n","            np.save(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_targets_tr\", targets_tr)\n","            np.save(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_embeds_va\", embeds_va)\n","            np.save(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_targets_va\", targets_va)\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"/{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions'] #bestmodelのpredictionをとりだす\n","    ### round\n","#     predictions *= 4\n","#     predictions = predictions.round() / 4\n","    valid_folds['pred'] = predictions\n","    valid_folds['pred'].hist(bins=100)\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds\n"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3d37dc96db1743b0b33c567f8c3e0d61","ad6a82c5e754438d9ba071c2b4a791ff","fd24b4905bca4fdb8372e23ffec85b72","cae0420598cf493ca05934f6489a6810","d7c8d81cd6ab4294a4cc70df96c5d6c6","a7833dacc53e46f896f8acaede6943b0","f9c4c741a35f4abf9fbb55493b725744","ed8cc56d2c1946d8a7d0cd299958132b","58d064a3a8b6480397b4b9b950d603cb","2e7b68e05c8a4a99a75d4aaf45828328","5f97d8c6f9f6462b8878630eaa2f2f30"]},"id":"6cc76b1e","executionInfo":{"status":"ok","timestamp":1654643967410,"user_tz":-540,"elapsed":56538956,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"}},"outputId":"af978c4a-93fe-4eb2-ffa1-b1feefc96355"},"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/833M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d37dc96db1743b0b33c567f8c3e0d61"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/2724] Elapsed 0m 1s (remain 80m 56s) Loss: 2.2188(2.2188) Grad: nan  LR: 0.00000003  \n","Epoch: [1][100/2724] Elapsed 1m 39s (remain 42m 59s) Loss: 1.3350(1.8140) Grad: 80580.1484  LR: 0.00000303  \n","Epoch: [1][200/2724] Elapsed 3m 17s (remain 41m 14s) Loss: 1.8555(1.6381) Grad: 77279.0078  LR: 0.00000603  \n","Epoch: [1][300/2724] Elapsed 4m 53s (remain 39m 26s) Loss: 0.8730(1.4850) Grad: 40054.4922  LR: 0.00000903  \n","Epoch: [1][400/2724] Elapsed 6m 30s (remain 37m 41s) Loss: 1.5039(1.3749) Grad: 81540.4453  LR: 0.00001203  \n","Epoch: [1][500/2724] Elapsed 8m 6s (remain 35m 59s) Loss: 0.9341(1.2959) Grad: 35454.3047  LR: 0.00001500  \n","Epoch: [1][600/2724] Elapsed 9m 43s (remain 34m 19s) Loss: 1.0078(1.2398) Grad: 34501.1875  LR: 0.00001500  \n","Epoch: [1][700/2724] Elapsed 11m 19s (remain 32m 40s) Loss: 0.9062(1.1973) Grad: 26275.1172  LR: 0.00001499  \n","Epoch: [1][800/2724] Elapsed 12m 55s (remain 31m 2s) Loss: 0.9233(1.1606) Grad: 34938.0156  LR: 0.00001497  \n","Epoch: [1][900/2724] Elapsed 14m 32s (remain 29m 24s) Loss: 0.9780(1.1333) Grad: 25867.2578  LR: 0.00001495  \n","Epoch: [1][1000/2724] Elapsed 16m 8s (remain 27m 47s) Loss: 0.8359(1.1069) Grad: 13663.0225  LR: 0.00001491  \n","Epoch: [1][1100/2724] Elapsed 17m 45s (remain 26m 10s) Loss: 0.9351(1.0873) Grad: 36149.4727  LR: 0.00001488  \n","Epoch: [1][1200/2724] Elapsed 19m 21s (remain 24m 33s) Loss: 0.7300(1.0689) Grad: 14962.3203  LR: 0.00001483  \n","Epoch: [1][1300/2724] Elapsed 20m 58s (remain 22m 56s) Loss: 0.8770(1.0560) Grad: 21646.8691  LR: 0.00001478  \n","Epoch: [1][1400/2724] Elapsed 22m 34s (remain 21m 19s) Loss: 0.7568(1.0419) Grad: 13645.4873  LR: 0.00001472  \n","Epoch: [1][1500/2724] Elapsed 24m 11s (remain 19m 42s) Loss: 0.7222(1.0304) Grad: 11650.2354  LR: 0.00001466  \n","Epoch: [1][1600/2724] Elapsed 25m 48s (remain 18m 5s) Loss: 1.0234(1.0197) Grad: 29681.3809  LR: 0.00001459  \n","Epoch: [1][1700/2724] Elapsed 27m 24s (remain 16m 29s) Loss: 0.8076(1.0115) Grad: 14366.1592  LR: 0.00001451  \n","Epoch: [1][1800/2724] Elapsed 29m 1s (remain 14m 52s) Loss: 0.9111(1.0029) Grad: 60395.3750  LR: 0.00001443  \n","Epoch: [1][1900/2724] Elapsed 30m 38s (remain 13m 15s) Loss: 0.7632(0.9961) Grad: 11344.0312  LR: 0.00001434  \n","Epoch: [1][2000/2724] Elapsed 32m 14s (remain 11m 39s) Loss: 0.7197(0.9888) Grad: 7170.7427  LR: 0.00001424  \n","Epoch: [1][2100/2724] Elapsed 33m 51s (remain 10m 2s) Loss: 0.8442(0.9822) Grad: 30839.9688  LR: 0.00001414  \n","Epoch: [1][2200/2724] Elapsed 35m 27s (remain 8m 25s) Loss: 0.7183(0.9757) Grad: 13758.9473  LR: 0.00001403  \n","Epoch: [1][2300/2724] Elapsed 37m 4s (remain 6m 48s) Loss: 1.1016(0.9713) Grad: 44863.4570  LR: 0.00001392  \n","Epoch: [1][2400/2724] Elapsed 38m 40s (remain 5m 12s) Loss: 0.8013(0.9663) Grad: 20596.8887  LR: 0.00001380  \n","Epoch: [1][2500/2724] Elapsed 40m 16s (remain 3m 35s) Loss: 1.0176(0.9616) Grad: 33079.1367  LR: 0.00001367  \n","Epoch: [1][2600/2724] Elapsed 41m 53s (remain 1m 58s) Loss: 0.8071(0.9582) Grad: 45945.1523  LR: 0.00001354  \n","Epoch: [1][2700/2724] Elapsed 43m 29s (remain 0m 22s) Loss: 0.8589(0.9543) Grad: 39681.5820  LR: 0.00001340  \n","Epoch: [1][2723/2724] Elapsed 43m 51s (remain 0m 0s) Loss: 0.7461(0.9532) Grad: 22383.7910  LR: 0.00001337  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Score: 0.8140\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/2724] Elapsed 0m 1s (remain 52m 12s) Loss: 0.7759(0.7759) Grad: nan  LR: 0.00001337  \n","Epoch: [2][100/2724] Elapsed 1m 37s (remain 42m 14s) Loss: 0.7344(0.7872) Grad: 134585.7188  LR: 0.00001322  \n","Epoch: [2][200/2724] Elapsed 3m 14s (remain 40m 35s) Loss: 0.7031(0.7866) Grad: 20302.1484  LR: 0.00001307  \n","Epoch: [2][300/2724] Elapsed 4m 50s (remain 38m 57s) Loss: 0.7798(0.7875) Grad: 38833.4609  LR: 0.00001292  \n","Epoch: [2][400/2724] Elapsed 6m 26s (remain 37m 20s) Loss: 0.7812(0.7917) Grad: 31670.3418  LR: 0.00001276  \n","Epoch: [2][500/2724] Elapsed 8m 3s (remain 35m 45s) Loss: 0.7251(0.7966) Grad: 32928.6094  LR: 0.00001260  \n","Epoch: [2][600/2724] Elapsed 9m 39s (remain 34m 8s) Loss: 0.7666(0.7960) Grad: 23711.2520  LR: 0.00001243  \n","Epoch: [2][700/2724] Elapsed 11m 16s (remain 32m 31s) Loss: 0.7573(0.7958) Grad: 23359.9785  LR: 0.00001226  \n","Epoch: [2][800/2724] Elapsed 12m 52s (remain 30m 55s) Loss: 0.8794(0.7950) Grad: 74093.0859  LR: 0.00001208  \n","Epoch: [2][900/2724] Elapsed 14m 29s (remain 29m 18s) Loss: 0.9810(0.7948) Grad: 138099.1719  LR: 0.00001190  \n","Epoch: [2][1000/2724] Elapsed 16m 5s (remain 27m 41s) Loss: 0.8306(0.7956) Grad: 39462.8516  LR: 0.00001171  \n","Epoch: [2][1100/2724] Elapsed 17m 41s (remain 26m 4s) Loss: 0.7505(0.7962) Grad: 19776.9570  LR: 0.00001152  \n","Epoch: [2][1200/2724] Elapsed 19m 17s (remain 24m 28s) Loss: 0.7339(0.7959) Grad: 21766.6523  LR: 0.00001133  \n","Epoch: [2][1300/2724] Elapsed 20m 54s (remain 22m 51s) Loss: 0.7383(0.7959) Grad: 28209.8438  LR: 0.00001113  \n","Epoch: [2][1400/2724] Elapsed 22m 30s (remain 21m 15s) Loss: 0.7139(0.7948) Grad: 15168.4238  LR: 0.00001093  \n","Epoch: [2][1500/2724] Elapsed 24m 6s (remain 19m 38s) Loss: 0.7461(0.7937) Grad: 16168.0303  LR: 0.00001073  \n","Epoch: [2][1600/2724] Elapsed 25m 42s (remain 18m 2s) Loss: 1.0820(0.7933) Grad: 66307.6875  LR: 0.00001052  \n","Epoch: [2][1700/2724] Elapsed 27m 19s (remain 16m 25s) Loss: 0.7422(0.7942) Grad: 17312.3926  LR: 0.00001031  \n","Epoch: [2][1800/2724] Elapsed 28m 55s (remain 14m 49s) Loss: 0.7969(0.7943) Grad: 38461.8984  LR: 0.00001010  \n","Epoch: [2][1900/2724] Elapsed 30m 31s (remain 13m 13s) Loss: 0.8027(0.7949) Grad: 41930.8320  LR: 0.00000989  \n","Epoch: [2][2000/2724] Elapsed 32m 8s (remain 11m 36s) Loss: 0.7861(0.7957) Grad: 28201.5234  LR: 0.00000967  \n","Epoch: [2][2100/2724] Elapsed 33m 44s (remain 10m 0s) Loss: 0.7896(0.7961) Grad: 44537.4688  LR: 0.00000946  \n","Epoch: [2][2200/2724] Elapsed 35m 20s (remain 8m 23s) Loss: 0.7983(0.7969) Grad: 33206.8711  LR: 0.00000924  \n","Epoch: [2][2300/2724] Elapsed 36m 56s (remain 6m 47s) Loss: 0.8989(0.7971) Grad: 53791.0195  LR: 0.00000901  \n","Epoch: [2][2400/2724] Elapsed 38m 33s (remain 5m 11s) Loss: 0.8408(0.7968) Grad: 96194.3125  LR: 0.00000879  \n","Epoch: [2][2500/2724] Elapsed 40m 9s (remain 3m 34s) Loss: 0.7090(0.7958) Grad: 22497.8906  LR: 0.00000857  \n","Epoch: [2][2600/2724] Elapsed 41m 45s (remain 1m 58s) Loss: 0.7144(0.7951) Grad: 40086.5781  LR: 0.00000834  \n","Epoch: [2][2700/2724] Elapsed 43m 22s (remain 0m 22s) Loss: 0.6987(0.7947) Grad: 27653.9648  LR: 0.00000812  \n","Epoch: [2][2723/2724] Elapsed 43m 44s (remain 0m 0s) Loss: 0.7588(0.7946) Grad: 79698.1641  LR: 0.00000807  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Score: 0.8314\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/2724] Elapsed 0m 1s (remain 53m 27s) Loss: 0.7695(0.7695) Grad: nan  LR: 0.00000806  \n","Epoch: [3][100/2724] Elapsed 1m 37s (remain 42m 14s) Loss: 0.7661(0.7592) Grad: 30223.2871  LR: 0.00000784  \n","Epoch: [3][200/2724] Elapsed 3m 13s (remain 40m 32s) Loss: 0.6948(0.7641) Grad: 21853.8320  LR: 0.00000761  \n","Epoch: [3][300/2724] Elapsed 4m 50s (remain 38m 54s) Loss: 0.9849(0.7638) Grad: 389934.1250  LR: 0.00000738  \n","Epoch: [3][400/2724] Elapsed 6m 26s (remain 37m 17s) Loss: 0.7969(0.7603) Grad: 74646.2656  LR: 0.00000716  \n","Epoch: [3][500/2724] Elapsed 8m 2s (remain 35m 40s) Loss: 1.0117(0.7589) Grad: 222010.7031  LR: 0.00000693  \n","Epoch: [3][600/2724] Elapsed 9m 38s (remain 34m 4s) Loss: 0.8594(0.7582) Grad: 107716.1250  LR: 0.00000671  \n","Epoch: [3][700/2724] Elapsed 11m 14s (remain 32m 27s) Loss: 0.8838(0.7566) Grad: 79655.2500  LR: 0.00000648  \n","Epoch: [3][800/2724] Elapsed 12m 51s (remain 30m 51s) Loss: 0.6958(0.7559) Grad: 33314.3086  LR: 0.00000626  \n","Epoch: [3][900/2724] Elapsed 14m 27s (remain 29m 15s) Loss: 0.7046(0.7553) Grad: 13164.1475  LR: 0.00000603  \n","Epoch: [3][1000/2724] Elapsed 16m 3s (remain 27m 38s) Loss: 0.7881(0.7554) Grad: 48476.5820  LR: 0.00000581  \n","Epoch: [3][1100/2724] Elapsed 17m 39s (remain 26m 2s) Loss: 0.7563(0.7549) Grad: 20338.5312  LR: 0.00000559  \n","Epoch: [3][1200/2724] Elapsed 19m 16s (remain 24m 26s) Loss: 0.7505(0.7547) Grad: 39350.4492  LR: 0.00000537  \n","Epoch: [3][1300/2724] Elapsed 20m 52s (remain 22m 49s) Loss: 0.6836(0.7552) Grad: 16098.5283  LR: 0.00000516  \n","Epoch: [3][1400/2724] Elapsed 22m 28s (remain 21m 13s) Loss: 0.7183(0.7547) Grad: 37025.0234  LR: 0.00000494  \n","Epoch: [3][1500/2724] Elapsed 24m 4s (remain 19m 37s) Loss: 0.7627(0.7543) Grad: 21133.8945  LR: 0.00000473  \n","Epoch: [3][1600/2724] Elapsed 25m 41s (remain 18m 1s) Loss: 0.7549(0.7531) Grad: 77709.9609  LR: 0.00000452  \n","Epoch: [3][1700/2724] Elapsed 27m 17s (remain 16m 24s) Loss: 0.7979(0.7529) Grad: 100066.7578  LR: 0.00000432  \n","Epoch: [3][1800/2724] Elapsed 28m 53s (remain 14m 48s) Loss: 0.6509(0.7527) Grad: 6778.2451  LR: 0.00000411  \n","Epoch: [3][1900/2724] Elapsed 30m 29s (remain 13m 12s) Loss: 0.7759(0.7529) Grad: 45248.6719  LR: 0.00000391  \n","Epoch: [3][2000/2724] Elapsed 32m 6s (remain 11m 35s) Loss: 0.7271(0.7522) Grad: 54933.7109  LR: 0.00000371  \n","Epoch: [3][2100/2724] Elapsed 33m 42s (remain 9m 59s) Loss: 0.6201(0.7520) Grad: 20994.4707  LR: 0.00000352  \n","Epoch: [3][2200/2724] Elapsed 35m 18s (remain 8m 23s) Loss: 0.7925(0.7520) Grad: 38820.4766  LR: 0.00000333  \n","Epoch: [3][2300/2724] Elapsed 36m 54s (remain 6m 47s) Loss: 0.7192(0.7523) Grad: 30424.0918  LR: 0.00000314  \n","Epoch: [3][2400/2724] Elapsed 38m 30s (remain 5m 10s) Loss: 0.8218(0.7526) Grad: 69376.7422  LR: 0.00000296  \n","Epoch: [3][2500/2724] Elapsed 40m 7s (remain 3m 34s) Loss: 0.7344(0.7523) Grad: 57109.1758  LR: 0.00000278  \n","Epoch: [3][2600/2724] Elapsed 41m 43s (remain 1m 58s) Loss: 0.6914(0.7519) Grad: 38279.9844  LR: 0.00000261  \n","Epoch: [3][2700/2724] Elapsed 43m 19s (remain 0m 22s) Loss: 0.7095(0.7516) Grad: 39191.0547  LR: 0.00000244  \n","Epoch: [3][2723/2724] Elapsed 43m 41s (remain 0m 0s) Loss: 0.7725(0.7516) Grad: 31669.1621  LR: 0.00000240  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Score: 0.8281\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/2724] Elapsed 0m 1s (remain 50m 38s) Loss: 0.7075(0.7075) Grad: nan  LR: 0.00000240  \n","Epoch: [4][100/2724] Elapsed 1m 37s (remain 42m 6s) Loss: 0.7510(0.7280) Grad: 67307.8281  LR: 0.00000224  \n","Epoch: [4][200/2724] Elapsed 3m 13s (remain 40m 28s) Loss: 0.8633(0.7323) Grad: 22263.1133  LR: 0.00000208  \n","Epoch: [4][300/2724] Elapsed 4m 49s (remain 38m 51s) Loss: 0.7769(0.7309) Grad: 7440.1572  LR: 0.00000192  \n","Epoch: [4][400/2724] Elapsed 6m 25s (remain 37m 15s) Loss: 0.7573(0.7314) Grad: 9693.7148  LR: 0.00000177  \n","Epoch: [4][500/2724] Elapsed 8m 2s (remain 35m 39s) Loss: 0.7183(0.7353) Grad: 17480.5781  LR: 0.00000163  \n","Epoch: [4][600/2724] Elapsed 9m 38s (remain 34m 2s) Loss: 0.7407(0.7355) Grad: 25121.1738  LR: 0.00000149  \n","Epoch: [4][700/2724] Elapsed 11m 14s (remain 32m 27s) Loss: 0.6621(0.7354) Grad: 9916.3232  LR: 0.00000136  \n","Epoch: [4][800/2724] Elapsed 12m 51s (remain 30m 51s) Loss: 0.6997(0.7356) Grad: 17152.5742  LR: 0.00000123  \n","Epoch: [4][900/2724] Elapsed 14m 27s (remain 29m 14s) Loss: 0.7188(0.7350) Grad: 23698.9199  LR: 0.00000111  \n","Epoch: [4][1000/2724] Elapsed 16m 3s (remain 27m 38s) Loss: 0.6914(0.7349) Grad: 14995.1865  LR: 0.00000099  \n","Epoch: [4][1100/2724] Elapsed 17m 39s (remain 26m 2s) Loss: 0.6753(0.7347) Grad: 3727.0393  LR: 0.00000088  \n","Epoch: [4][1200/2724] Elapsed 19m 15s (remain 24m 25s) Loss: 0.6826(0.7338) Grad: 19393.6621  LR: 0.00000078  \n","Epoch: [4][1300/2724] Elapsed 20m 52s (remain 22m 49s) Loss: 0.7583(0.7342) Grad: 37587.7070  LR: 0.00000068  \n","Epoch: [4][1400/2724] Elapsed 22m 28s (remain 21m 13s) Loss: 0.7095(0.7344) Grad: 25890.5566  LR: 0.00000059  \n","Epoch: [4][1500/2724] Elapsed 24m 4s (remain 19m 36s) Loss: 0.8594(0.7348) Grad: 12630.4941  LR: 0.00000051  \n","Epoch: [4][1600/2724] Elapsed 25m 40s (remain 18m 0s) Loss: 0.7100(0.7349) Grad: 35693.0312  LR: 0.00000043  \n","Epoch: [4][1700/2724] Elapsed 27m 16s (remain 16m 24s) Loss: 0.6816(0.7351) Grad: 14118.6514  LR: 0.00000036  \n","Epoch: [4][1800/2724] Elapsed 28m 53s (remain 14m 48s) Loss: 0.8369(0.7351) Grad: 33761.7227  LR: 0.00000029  \n","Epoch: [4][1900/2724] Elapsed 30m 29s (remain 13m 12s) Loss: 0.6797(0.7347) Grad: 7545.1841  LR: 0.00000023  \n","Epoch: [4][2000/2724] Elapsed 32m 5s (remain 11m 35s) Loss: 0.6895(0.7340) Grad: 15378.4678  LR: 0.00000018  \n","Epoch: [4][2100/2724] Elapsed 33m 42s (remain 9m 59s) Loss: 0.7139(0.7340) Grad: 10660.9482  LR: 0.00000013  \n","Epoch: [4][2200/2724] Elapsed 35m 18s (remain 8m 23s) Loss: 0.8057(0.7340) Grad: 48872.3750  LR: 0.00000009  \n","Epoch: [4][2300/2724] Elapsed 36m 54s (remain 6m 47s) Loss: 0.6484(0.7339) Grad: 11782.1475  LR: 0.00000006  \n","Epoch: [4][2400/2724] Elapsed 38m 30s (remain 5m 10s) Loss: 0.6846(0.7339) Grad: 5639.4995  LR: 0.00000004  \n","Epoch: [4][2500/2724] Elapsed 40m 7s (remain 3m 34s) Loss: 0.7173(0.7339) Grad: 21189.7930  LR: 0.00000002  \n","Epoch: [4][2600/2724] Elapsed 41m 43s (remain 1m 58s) Loss: 0.6982(0.7334) Grad: 34762.6641  LR: 0.00000001  \n","Epoch: [4][2700/2724] Elapsed 43m 19s (remain 0m 22s) Loss: 0.7036(0.7334) Grad: 15010.1895  LR: 0.00000000  \n","Epoch: [4][2723/2724] Elapsed 43m 41s (remain 0m 0s) Loss: 0.7925(0.7334) Grad: 13648.0918  LR: 0.00000000  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - Score: 0.8315\n","========== fold: 0 result ==========\n","Score: 0.8315\n","========== fold: 1 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/2697] Elapsed 0m 2s (remain 101m 9s) Loss: 1.7598(1.7598) Grad: nan  LR: 0.00000003  \n","Epoch: [1][100/2697] Elapsed 1m 38s (remain 42m 14s) Loss: 1.5918(1.7938) Grad: 78888.0938  LR: 0.00000303  \n","Epoch: [1][200/2697] Elapsed 3m 14s (remain 40m 19s) Loss: 0.9834(1.6218) Grad: 51107.4023  LR: 0.00000603  \n","Epoch: [1][300/2697] Elapsed 4m 51s (remain 38m 37s) Loss: 0.8750(1.4323) Grad: 35864.6602  LR: 0.00000903  \n","Epoch: [1][400/2697] Elapsed 6m 27s (remain 36m 58s) Loss: 0.8784(1.3195) Grad: 25583.5781  LR: 0.00001203  \n","Epoch: [1][500/2697] Elapsed 8m 3s (remain 35m 20s) Loss: 0.7759(1.2417) Grad: 19324.5254  LR: 0.00001500  \n","Epoch: [1][600/2697] Elapsed 9m 40s (remain 33m 42s) Loss: 1.1055(1.1910) Grad: 34370.3828  LR: 0.00001500  \n","Epoch: [1][700/2697] Elapsed 11m 16s (remain 32m 5s) Loss: 0.9214(1.1503) Grad: 34194.4648  LR: 0.00001499  \n","Epoch: [1][800/2697] Elapsed 12m 52s (remain 30m 28s) Loss: 1.5938(1.1462) Grad: 29862.5195  LR: 0.00001497  \n","Epoch: [1][900/2697] Elapsed 14m 28s (remain 28m 51s) Loss: 1.4238(1.1714) Grad: 8945.5576  LR: 0.00001494  \n","Epoch: [1][1000/2697] Elapsed 16m 5s (remain 27m 15s) Loss: 1.0771(1.1874) Grad: 7748.0952  LR: 0.00001491  \n","Epoch: [1][1100/2697] Elapsed 17m 41s (remain 25m 38s) Loss: 1.2129(1.1943) Grad: 4167.9097  LR: 0.00001487  \n","Epoch: [1][1200/2697] Elapsed 19m 17s (remain 24m 2s) Loss: 0.8481(1.1891) Grad: 5722.3247  LR: 0.00001483  \n","Epoch: [1][1300/2697] Elapsed 20m 54s (remain 22m 25s) Loss: 1.1289(1.1712) Grad: 9028.2393  LR: 0.00001478  \n","Epoch: [1][1400/2697] Elapsed 22m 30s (remain 20m 49s) Loss: 0.9629(1.1528) Grad: 18842.0098  LR: 0.00001472  \n","Epoch: [1][1500/2697] Elapsed 24m 6s (remain 19m 12s) Loss: 0.8809(1.1374) Grad: 3279.1460  LR: 0.00001465  \n","Epoch: [1][1600/2697] Elapsed 25m 43s (remain 17m 36s) Loss: 0.8833(1.1230) Grad: 2079.6914  LR: 0.00001458  \n","Epoch: [1][1700/2697] Elapsed 27m 19s (remain 15m 59s) Loss: 1.0645(1.1113) Grad: 6513.1001  LR: 0.00001450  \n","Epoch: [1][1800/2697] Elapsed 28m 55s (remain 14m 23s) Loss: 0.7598(1.0996) Grad: 1438.8628  LR: 0.00001442  \n","Epoch: [1][1900/2697] Elapsed 30m 31s (remain 12m 47s) Loss: 0.9004(1.0904) Grad: 6144.7549  LR: 0.00001432  \n","Epoch: [1][2000/2697] Elapsed 32m 8s (remain 11m 10s) Loss: 0.8140(1.0809) Grad: 1718.3048  LR: 0.00001423  \n","Epoch: [1][2100/2697] Elapsed 33m 44s (remain 9m 34s) Loss: 0.8770(1.0730) Grad: 3660.3938  LR: 0.00001412  \n","Epoch: [1][2200/2697] Elapsed 35m 20s (remain 7m 57s) Loss: 1.1035(1.0642) Grad: 2608.0093  LR: 0.00001401  \n","Epoch: [1][2300/2697] Elapsed 36m 57s (remain 6m 21s) Loss: 0.9839(1.0564) Grad: 2864.4004  LR: 0.00001389  \n","Epoch: [1][2400/2697] Elapsed 38m 33s (remain 4m 45s) Loss: 0.9336(1.0495) Grad: 2287.5842  LR: 0.00001377  \n","Epoch: [1][2500/2697] Elapsed 40m 10s (remain 3m 8s) Loss: 0.8848(1.0427) Grad: 1482.6405  LR: 0.00001364  \n","Epoch: [1][2600/2697] Elapsed 41m 46s (remain 1m 32s) Loss: 0.8369(1.0360) Grad: 1785.9772  LR: 0.00001351  \n","Epoch: [1][2696/2697] Elapsed 43m 18s (remain 0m 0s) Loss: 0.8096(1.0302) Grad: 1323.7820  LR: 0.00001337  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Score: 0.8142\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/2697] Elapsed 0m 1s (remain 52m 9s) Loss: 0.7783(0.7783) Grad: nan  LR: 0.00001337  \n","Epoch: [2][100/2697] Elapsed 1m 37s (remain 41m 50s) Loss: 0.7979(0.8121) Grad: 66327.0312  LR: 0.00001323  \n","Epoch: [2][200/2697] Elapsed 3m 13s (remain 40m 8s) Loss: 0.7334(0.8147) Grad: 23080.5391  LR: 0.00001308  \n","Epoch: [2][300/2697] Elapsed 4m 50s (remain 38m 30s) Loss: 0.8911(0.8129) Grad: 49499.9492  LR: 0.00001292  \n","Epoch: [2][400/2697] Elapsed 6m 26s (remain 36m 53s) Loss: 1.2051(0.8133) Grad: 238164.6250  LR: 0.00001276  \n","Epoch: [2][500/2697] Elapsed 8m 2s (remain 35m 16s) Loss: 0.7876(0.8125) Grad: 91471.5625  LR: 0.00001260  \n","Epoch: [2][600/2697] Elapsed 9m 39s (remain 33m 40s) Loss: 0.7373(0.8117) Grad: 15564.3584  LR: 0.00001242  \n","Epoch: [2][700/2697] Elapsed 11m 15s (remain 32m 3s) Loss: 0.8071(0.8122) Grad: 23168.9453  LR: 0.00001225  \n","Epoch: [2][800/2697] Elapsed 12m 52s (remain 30m 27s) Loss: 0.9023(0.8098) Grad: 199706.6562  LR: 0.00001207  \n","Epoch: [2][900/2697] Elapsed 14m 28s (remain 28m 51s) Loss: 0.8193(0.8097) Grad: 27036.4434  LR: 0.00001189  \n","Epoch: [2][1000/2697] Elapsed 16m 4s (remain 27m 14s) Loss: 0.6792(0.8074) Grad: 12418.2344  LR: 0.00001170  \n","Epoch: [2][1100/2697] Elapsed 17m 41s (remain 25m 38s) Loss: 0.8823(0.8057) Grad: 25517.7910  LR: 0.00001151  \n","Epoch: [2][1200/2697] Elapsed 19m 17s (remain 24m 1s) Loss: 0.7822(0.8045) Grad: 25595.9219  LR: 0.00001131  \n","Epoch: [2][1300/2697] Elapsed 20m 53s (remain 22m 25s) Loss: 0.7822(0.8052) Grad: 16374.8486  LR: 0.00001111  \n","Epoch: [2][1400/2697] Elapsed 22m 30s (remain 20m 48s) Loss: 0.8076(0.8042) Grad: 19455.9375  LR: 0.00001091  \n","Epoch: [2][1500/2697] Elapsed 24m 6s (remain 19m 12s) Loss: 0.8535(0.8035) Grad: 28321.1758  LR: 0.00001071  \n","Epoch: [2][1600/2697] Elapsed 25m 42s (remain 17m 36s) Loss: 0.7637(0.8036) Grad: 17772.8555  LR: 0.00001050  \n","Epoch: [2][1700/2697] Elapsed 27m 19s (remain 15m 59s) Loss: 0.7583(0.8030) Grad: 37487.0430  LR: 0.00001029  \n","Epoch: [2][1800/2697] Elapsed 28m 55s (remain 14m 23s) Loss: 0.6929(0.8029) Grad: 11687.9893  LR: 0.00001007  \n","Epoch: [2][1900/2697] Elapsed 30m 31s (remain 12m 47s) Loss: 0.7080(0.8024) Grad: 19567.4785  LR: 0.00000986  \n","Epoch: [2][2000/2697] Elapsed 32m 8s (remain 11m 10s) Loss: 0.7783(0.8023) Grad: 17876.3594  LR: 0.00000964  \n","Epoch: [2][2100/2697] Elapsed 33m 44s (remain 9m 34s) Loss: 0.7031(0.8026) Grad: 18312.0527  LR: 0.00000942  \n","Epoch: [2][2200/2697] Elapsed 35m 20s (remain 7m 57s) Loss: 0.8203(0.8022) Grad: 90589.0703  LR: 0.00000919  \n","Epoch: [2][2300/2697] Elapsed 36m 57s (remain 6m 21s) Loss: 0.7158(0.8018) Grad: 17381.6152  LR: 0.00000897  \n","Epoch: [2][2400/2697] Elapsed 38m 33s (remain 4m 45s) Loss: 0.7686(0.8009) Grad: 28981.8633  LR: 0.00000874  \n","Epoch: [2][2500/2697] Elapsed 40m 9s (remain 3m 8s) Loss: 0.8945(0.8013) Grad: 68766.5547  LR: 0.00000852  \n","Epoch: [2][2600/2697] Elapsed 41m 46s (remain 1m 32s) Loss: 0.7861(0.8010) Grad: 41063.1016  LR: 0.00000829  \n","Epoch: [2][2696/2697] Elapsed 43m 18s (remain 0m 0s) Loss: 0.7197(0.8002) Grad: 29071.1523  LR: 0.00000807  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Score: 0.8271\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/2697] Elapsed 0m 1s (remain 53m 51s) Loss: 0.7476(0.7476) Grad: nan  LR: 0.00000807  \n","Epoch: [3][100/2697] Elapsed 1m 37s (remain 41m 52s) Loss: 0.6919(0.7758) Grad: 33448.9609  LR: 0.00000784  \n","Epoch: [3][200/2697] Elapsed 3m 14s (remain 40m 9s) Loss: 0.7642(0.7799) Grad: 42088.4453  LR: 0.00000761  \n","Epoch: [3][300/2697] Elapsed 4m 50s (remain 38m 32s) Loss: 0.8579(0.7772) Grad: 51663.1289  LR: 0.00000738  \n","Epoch: [3][400/2697] Elapsed 6m 27s (remain 36m 56s) Loss: 0.7124(0.7757) Grad: 27089.3750  LR: 0.00000715  \n","Epoch: [3][500/2697] Elapsed 8m 3s (remain 35m 19s) Loss: 0.8047(0.7776) Grad: 31191.6562  LR: 0.00000693  \n","Epoch: [3][600/2697] Elapsed 9m 39s (remain 33m 42s) Loss: 0.7617(0.7771) Grad: 11201.7773  LR: 0.00000670  \n","Epoch: [3][700/2697] Elapsed 11m 16s (remain 32m 5s) Loss: 0.7329(0.7777) Grad: 14137.0068  LR: 0.00000647  \n","Epoch: [3][800/2697] Elapsed 12m 52s (remain 30m 28s) Loss: 0.7637(0.7786) Grad: 58452.6211  LR: 0.00000624  \n","Epoch: [3][900/2697] Elapsed 14m 29s (remain 28m 52s) Loss: 0.8350(0.7786) Grad: 43468.8906  LR: 0.00000602  \n","Epoch: [3][1000/2697] Elapsed 16m 5s (remain 27m 15s) Loss: 0.7197(0.7772) Grad: 19714.2441  LR: 0.00000580  \n","Epoch: [3][1100/2697] Elapsed 17m 41s (remain 25m 39s) Loss: 0.7095(0.7761) Grad: 20120.2988  LR: 0.00000557  \n","Epoch: [3][1200/2697] Elapsed 19m 18s (remain 24m 2s) Loss: 1.0010(0.7759) Grad: 182590.8906  LR: 0.00000535  \n","Epoch: [3][1300/2697] Elapsed 20m 54s (remain 22m 26s) Loss: 0.7476(0.7760) Grad: 21110.1484  LR: 0.00000513  \n","Epoch: [3][1400/2697] Elapsed 22m 30s (remain 20m 49s) Loss: 0.6855(0.7756) Grad: 9643.6084  LR: 0.00000492  \n","Epoch: [3][1500/2697] Elapsed 24m 7s (remain 19m 13s) Loss: 0.8682(0.7749) Grad: 48724.7500  LR: 0.00000470  \n","Epoch: [3][1600/2697] Elapsed 25m 43s (remain 17m 36s) Loss: 0.8027(0.7749) Grad: 27039.4336  LR: 0.00000449  \n","Epoch: [3][1700/2697] Elapsed 27m 19s (remain 16m 0s) Loss: 0.7109(0.7751) Grad: 15642.0645  LR: 0.00000428  \n","Epoch: [3][1800/2697] Elapsed 28m 56s (remain 14m 23s) Loss: 0.7773(0.7751) Grad: 20626.4102  LR: 0.00000408  \n","Epoch: [3][1900/2697] Elapsed 30m 32s (remain 12m 47s) Loss: 0.7798(0.7754) Grad: 17630.9883  LR: 0.00000388  \n","Epoch: [3][2000/2697] Elapsed 32m 8s (remain 11m 10s) Loss: 0.7026(0.7750) Grad: 10476.3896  LR: 0.00000368  \n","Epoch: [3][2100/2697] Elapsed 33m 45s (remain 9m 34s) Loss: 0.8271(0.7745) Grad: 29197.5586  LR: 0.00000348  \n","Epoch: [3][2200/2697] Elapsed 35m 21s (remain 7m 58s) Loss: 0.7500(0.7748) Grad: 20235.1504  LR: 0.00000329  \n","Epoch: [3][2300/2697] Elapsed 36m 57s (remain 6m 21s) Loss: 1.1299(0.7748) Grad: 30372.3145  LR: 0.00000310  \n","Epoch: [3][2400/2697] Elapsed 38m 34s (remain 4m 45s) Loss: 0.7485(0.7743) Grad: 15714.4561  LR: 0.00000292  \n","Epoch: [3][2500/2697] Elapsed 40m 10s (remain 3m 8s) Loss: 0.9170(0.7745) Grad: 12585.0576  LR: 0.00000274  \n","Epoch: [3][2600/2697] Elapsed 41m 46s (remain 1m 32s) Loss: 0.7090(0.7749) Grad: 7547.3843  LR: 0.00000257  \n","Epoch: [3][2696/2697] Elapsed 43m 19s (remain 0m 0s) Loss: 0.6860(0.7755) Grad: 6037.9302  LR: 0.00000240  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Score: 0.8307\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/2697] Elapsed 0m 1s (remain 53m 59s) Loss: 0.7954(0.7954) Grad: nan  LR: 0.00000240  \n","Epoch: [4][100/2697] Elapsed 1m 37s (remain 41m 53s) Loss: 0.7017(0.7519) Grad: 49711.9297  LR: 0.00000224  \n","Epoch: [4][200/2697] Elapsed 3m 14s (remain 40m 10s) Loss: 0.7407(0.7541) Grad: 100968.9062  LR: 0.00000208  \n","Epoch: [4][300/2697] Elapsed 4m 50s (remain 38m 31s) Loss: 0.8286(0.7570) Grad: nan  LR: 0.00000192  \n","Epoch: [4][400/2697] Elapsed 6m 26s (remain 36m 54s) Loss: 0.7363(0.7541) Grad: 45310.5508  LR: 0.00000177  \n","Epoch: [4][500/2697] Elapsed 8m 3s (remain 35m 17s) Loss: 0.7378(0.7583) Grad: 46933.8594  LR: 0.00000162  \n","Epoch: [4][600/2697] Elapsed 9m 39s (remain 33m 40s) Loss: 0.7983(0.7584) Grad: 79815.2109  LR: 0.00000148  \n","Epoch: [4][700/2697] Elapsed 11m 15s (remain 32m 4s) Loss: 0.6963(0.7593) Grad: 43483.8906  LR: 0.00000135  \n","Epoch: [4][800/2697] Elapsed 12m 52s (remain 30m 27s) Loss: 0.7212(0.7577) Grad: 18421.9609  LR: 0.00000122  \n","Epoch: [4][900/2697] Elapsed 14m 28s (remain 28m 50s) Loss: 0.6802(0.7576) Grad: 11136.9023  LR: 0.00000110  \n","Epoch: [4][1000/2697] Elapsed 16m 4s (remain 27m 14s) Loss: 0.6914(0.7582) Grad: 14709.6836  LR: 0.00000098  \n","Epoch: [4][1100/2697] Elapsed 17m 41s (remain 25m 38s) Loss: 0.7075(0.7575) Grad: 17325.9238  LR: 0.00000087  \n","Epoch: [4][1200/2697] Elapsed 19m 17s (remain 24m 1s) Loss: 0.6606(0.7582) Grad: 24050.6133  LR: 0.00000077  \n","Epoch: [4][1300/2697] Elapsed 20m 54s (remain 22m 25s) Loss: 0.8350(0.7576) Grad: 41924.1328  LR: 0.00000067  \n","Epoch: [4][1400/2697] Elapsed 22m 30s (remain 20m 49s) Loss: 0.7769(0.7577) Grad: 34461.0000  LR: 0.00000058  \n","Epoch: [4][1500/2697] Elapsed 24m 6s (remain 19m 12s) Loss: 0.8096(0.7576) Grad: 22394.7949  LR: 0.00000049  \n","Epoch: [4][1600/2697] Elapsed 25m 43s (remain 17m 36s) Loss: 0.7520(0.7574) Grad: 28478.0859  LR: 0.00000042  \n","Epoch: [4][1700/2697] Elapsed 27m 19s (remain 16m 0s) Loss: 0.7178(0.7578) Grad: 22325.4258  LR: 0.00000034  \n","Epoch: [4][1800/2697] Elapsed 28m 56s (remain 14m 23s) Loss: 0.8281(0.7574) Grad: 31081.1309  LR: 0.00000028  \n","Epoch: [4][1900/2697] Elapsed 30m 32s (remain 12m 47s) Loss: 0.7085(0.7576) Grad: 6788.5391  LR: 0.00000022  \n","Epoch: [4][2000/2697] Elapsed 32m 8s (remain 11m 10s) Loss: 0.8823(0.7569) Grad: 20942.0859  LR: 0.00000017  \n","Epoch: [4][2100/2697] Elapsed 33m 45s (remain 9m 34s) Loss: 0.7319(0.7571) Grad: 21390.2773  LR: 0.00000012  \n","Epoch: [4][2200/2697] Elapsed 35m 21s (remain 7m 58s) Loss: 0.6440(0.7569) Grad: 9855.2900  LR: 0.00000009  \n","Epoch: [4][2300/2697] Elapsed 36m 58s (remain 6m 21s) Loss: 0.7715(0.7564) Grad: 35164.3516  LR: 0.00000005  \n","Epoch: [4][2400/2697] Elapsed 38m 34s (remain 4m 45s) Loss: 0.7334(0.7564) Grad: 16353.4443  LR: 0.00000003  \n","Epoch: [4][2500/2697] Elapsed 40m 11s (remain 3m 8s) Loss: 0.6470(0.7563) Grad: 8094.1465  LR: 0.00000001  \n","Epoch: [4][2600/2697] Elapsed 41m 47s (remain 1m 32s) Loss: 0.6660(0.7560) Grad: 3883.4543  LR: 0.00000000  \n","Epoch: [4][2696/2697] Elapsed 43m 19s (remain 0m 0s) Loss: 0.7822(0.7561) Grad: 19338.6484  LR: 0.00000000  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - Score: 0.8331\n","========== fold: 1 result ==========\n","Score: 0.8331\n","========== fold: 2 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/2727] Elapsed 0m 2s (remain 131m 11s) Loss: 1.9121(1.9121) Grad: nan  LR: 0.00000003  \n","Epoch: [1][100/2727] Elapsed 1m 39s (remain 42m 56s) Loss: 1.8008(1.7528) Grad: 129259.6875  LR: 0.00000303  \n","Epoch: [1][200/2727] Elapsed 3m 15s (remain 40m 57s) Loss: 1.1787(1.6879) Grad: 84870.3203  LR: 0.00000603  \n","Epoch: [1][300/2727] Elapsed 4m 51s (remain 39m 12s) Loss: 0.9229(1.5199) Grad: 48375.6992  LR: 0.00000903  \n","Epoch: [1][400/2727] Elapsed 6m 28s (remain 37m 32s) Loss: 0.7998(1.3934) Grad: 18567.5332  LR: 0.00001203  \n","Epoch: [1][500/2727] Elapsed 8m 4s (remain 35m 53s) Loss: 0.9438(1.3088) Grad: 30275.5254  LR: 0.00001500  \n","Epoch: [1][600/2727] Elapsed 9m 41s (remain 34m 15s) Loss: 0.8232(1.2479) Grad: 16785.2715  LR: 0.00001500  \n","Epoch: [1][700/2727] Elapsed 11m 17s (remain 32m 37s) Loss: 0.7905(1.2036) Grad: 14634.6387  LR: 0.00001499  \n","Epoch: [1][800/2727] Elapsed 12m 53s (remain 31m 0s) Loss: 0.8354(1.1688) Grad: 14739.5938  LR: 0.00001497  \n","Epoch: [1][900/2727] Elapsed 14m 30s (remain 29m 23s) Loss: 1.0732(1.1408) Grad: 47637.9609  LR: 0.00001495  \n","Epoch: [1][1000/2727] Elapsed 16m 6s (remain 27m 46s) Loss: 0.8389(1.1152) Grad: 22990.0078  LR: 0.00001491  \n","Epoch: [1][1100/2727] Elapsed 17m 43s (remain 26m 10s) Loss: 1.0176(1.0966) Grad: 19684.9863  LR: 0.00001488  \n","Epoch: [1][1200/2727] Elapsed 19m 19s (remain 24m 33s) Loss: 0.9395(1.0789) Grad: 18786.6602  LR: 0.00001483  \n","Epoch: [1][1300/2727] Elapsed 20m 56s (remain 22m 56s) Loss: 0.7554(1.0625) Grad: 19636.2773  LR: 0.00001478  \n","Epoch: [1][1400/2727] Elapsed 22m 32s (remain 21m 20s) Loss: 1.1963(1.0492) Grad: 81020.8750  LR: 0.00001472  \n","Epoch: [1][1500/2727] Elapsed 24m 8s (remain 19m 43s) Loss: 0.7847(1.0373) Grad: 12727.2002  LR: 0.00001466  \n","Epoch: [1][1600/2727] Elapsed 25m 45s (remain 18m 6s) Loss: 0.8652(1.0260) Grad: 12068.2920  LR: 0.00001459  \n","Epoch: [1][1700/2727] Elapsed 27m 21s (remain 16m 30s) Loss: 0.7153(1.0172) Grad: 7346.2559  LR: 0.00001451  \n","Epoch: [1][1800/2727] Elapsed 28m 58s (remain 14m 53s) Loss: 0.7783(1.0083) Grad: 11031.9141  LR: 0.00001443  \n","Epoch: [1][1900/2727] Elapsed 30m 34s (remain 13m 17s) Loss: 0.7847(1.0016) Grad: 14924.3760  LR: 0.00001434  \n","Epoch: [1][2000/2727] Elapsed 32m 11s (remain 11m 40s) Loss: 0.8276(0.9942) Grad: 11448.4033  LR: 0.00001424  \n","Epoch: [1][2100/2727] Elapsed 33m 47s (remain 10m 4s) Loss: 0.9536(0.9873) Grad: 35097.9648  LR: 0.00001414  \n","Epoch: [1][2200/2727] Elapsed 35m 23s (remain 8m 27s) Loss: 0.6924(0.9813) Grad: 8053.7388  LR: 0.00001403  \n","Epoch: [1][2300/2727] Elapsed 37m 0s (remain 6m 51s) Loss: 0.8838(0.9759) Grad: 32671.1152  LR: 0.00001392  \n","Epoch: [1][2400/2727] Elapsed 38m 36s (remain 5m 14s) Loss: 0.8130(0.9715) Grad: 22683.9805  LR: 0.00001380  \n","Epoch: [1][2500/2727] Elapsed 40m 13s (remain 3m 38s) Loss: 0.7485(0.9665) Grad: 11960.3867  LR: 0.00001367  \n","Epoch: [1][2600/2727] Elapsed 41m 49s (remain 2m 1s) Loss: 0.8369(0.9624) Grad: 48347.6172  LR: 0.00001354  \n","Epoch: [1][2700/2727] Elapsed 43m 26s (remain 0m 25s) Loss: 0.6465(0.9574) Grad: 7221.3516  LR: 0.00001341  \n","Epoch: [1][2726/2727] Elapsed 43m 51s (remain 0m 0s) Loss: 0.7900(0.9563) Grad: 27113.9453  LR: 0.00001337  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Score: 0.8340\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/2727] Elapsed 0m 1s (remain 64m 41s) Loss: 0.7817(0.7817) Grad: nan  LR: 0.00001337  \n","Epoch: [2][100/2727] Elapsed 1m 37s (remain 42m 25s) Loss: 0.8037(0.7906) Grad: 52003.5352  LR: 0.00001322  \n","Epoch: [2][200/2727] Elapsed 3m 14s (remain 40m 42s) Loss: 0.7598(0.7952) Grad: 59771.3320  LR: 0.00001308  \n","Epoch: [2][300/2727] Elapsed 4m 50s (remain 39m 3s) Loss: 0.7002(0.7957) Grad: 26262.5703  LR: 0.00001292  \n","Epoch: [2][400/2727] Elapsed 6m 27s (remain 37m 26s) Loss: 0.7188(0.7922) Grad: 37714.9336  LR: 0.00001276  \n","Epoch: [2][500/2727] Elapsed 8m 3s (remain 35m 48s) Loss: 0.8164(0.7902) Grad: 67348.7578  LR: 0.00001260  \n","Epoch: [2][600/2727] Elapsed 9m 40s (remain 34m 12s) Loss: 0.8252(0.7879) Grad: 73017.8438  LR: 0.00001243  \n","Epoch: [2][700/2727] Elapsed 11m 16s (remain 32m 35s) Loss: 0.8560(0.7889) Grad: 41511.8047  LR: 0.00001226  \n","Epoch: [2][800/2727] Elapsed 12m 53s (remain 30m 58s) Loss: 0.7866(0.7902) Grad: 69620.0469  LR: 0.00001208  \n","Epoch: [2][900/2727] Elapsed 14m 29s (remain 29m 22s) Loss: 0.7173(0.7914) Grad: 13222.4688  LR: 0.00001190  \n","Epoch: [2][1000/2727] Elapsed 16m 5s (remain 27m 45s) Loss: 0.9985(0.7920) Grad: 75982.6562  LR: 0.00001171  \n","Epoch: [2][1100/2727] Elapsed 17m 42s (remain 26m 8s) Loss: 0.7466(0.7925) Grad: 24739.8086  LR: 0.00001153  \n","Epoch: [2][1200/2727] Elapsed 19m 18s (remain 24m 32s) Loss: 0.7310(0.7926) Grad: 13664.5488  LR: 0.00001133  \n","Epoch: [2][1300/2727] Elapsed 20m 55s (remain 22m 55s) Loss: 0.7485(0.7925) Grad: 28611.0684  LR: 0.00001114  \n","Epoch: [2][1400/2727] Elapsed 22m 31s (remain 21m 19s) Loss: 0.8511(0.7933) Grad: 27899.0176  LR: 0.00001094  \n","Epoch: [2][1500/2727] Elapsed 24m 8s (remain 19m 42s) Loss: 0.7607(0.7925) Grad: 22170.4043  LR: 0.00001073  \n","Epoch: [2][1600/2727] Elapsed 25m 44s (remain 18m 6s) Loss: 0.7246(0.7923) Grad: 13397.8379  LR: 0.00001053  \n","Epoch: [2][1700/2727] Elapsed 27m 20s (remain 16m 29s) Loss: 0.7593(0.7925) Grad: 29512.5625  LR: 0.00001032  \n","Epoch: [2][1800/2727] Elapsed 28m 58s (remain 14m 53s) Loss: 0.8306(0.7921) Grad: 30351.2109  LR: 0.00001011  \n","Epoch: [2][1900/2727] Elapsed 30m 34s (remain 13m 17s) Loss: 0.7349(0.7921) Grad: 20793.7754  LR: 0.00000990  \n","Epoch: [2][2000/2727] Elapsed 32m 11s (remain 11m 40s) Loss: 0.6680(0.7926) Grad: 11203.4199  LR: 0.00000968  \n","Epoch: [2][2100/2727] Elapsed 33m 47s (remain 10m 4s) Loss: 0.8418(0.7927) Grad: 84358.9297  LR: 0.00000946  \n","Epoch: [2][2200/2727] Elapsed 35m 23s (remain 8m 27s) Loss: 0.8447(0.7929) Grad: 57419.4844  LR: 0.00000924  \n","Epoch: [2][2300/2727] Elapsed 37m 0s (remain 6m 51s) Loss: 0.9927(0.7932) Grad: 97613.0391  LR: 0.00000902  \n","Epoch: [2][2400/2727] Elapsed 38m 36s (remain 5m 14s) Loss: 0.8501(0.7927) Grad: 41396.9297  LR: 0.00000880  \n","Epoch: [2][2500/2727] Elapsed 40m 13s (remain 3m 38s) Loss: 0.7842(0.7929) Grad: 27874.5859  LR: 0.00000858  \n","Epoch: [2][2600/2727] Elapsed 41m 49s (remain 2m 1s) Loss: 0.7603(0.7928) Grad: 16881.1523  LR: 0.00000835  \n","Epoch: [2][2700/2727] Elapsed 43m 26s (remain 0m 25s) Loss: 0.7515(0.7930) Grad: 44149.3203  LR: 0.00000813  \n","Epoch: [2][2726/2727] Elapsed 43m 51s (remain 0m 0s) Loss: 0.7344(0.7929) Grad: 38882.0469  LR: 0.00000807  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Score: 0.8260\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/2727] Elapsed 0m 1s (remain 54m 20s) Loss: 0.9609(0.9609) Grad: nan  LR: 0.00000807  \n","Epoch: [3][100/2727] Elapsed 1m 37s (remain 42m 18s) Loss: 0.7231(0.7447) Grad: 42014.0938  LR: 0.00000784  \n","Epoch: [3][200/2727] Elapsed 3m 14s (remain 40m 38s) Loss: 0.7192(0.7514) Grad: 24242.5898  LR: 0.00000761  \n","Epoch: [3][300/2727] Elapsed 4m 50s (remain 39m 1s) Loss: 0.7993(0.7522) Grad: 121997.6250  LR: 0.00000739  \n","Epoch: [3][400/2727] Elapsed 6m 27s (remain 37m 25s) Loss: 0.6948(0.7524) Grad: 10335.6270  LR: 0.00000716  \n","Epoch: [3][500/2727] Elapsed 8m 3s (remain 35m 48s) Loss: 0.7500(0.7534) Grad: 56968.8711  LR: 0.00000694  \n","Epoch: [3][600/2727] Elapsed 9m 40s (remain 34m 11s) Loss: 0.7056(0.7524) Grad: 24888.5586  LR: 0.00000671  \n","Epoch: [3][700/2727] Elapsed 11m 16s (remain 32m 34s) Loss: 1.0234(0.7523) Grad: 58363.9180  LR: 0.00000649  \n","Epoch: [3][800/2727] Elapsed 12m 52s (remain 30m 58s) Loss: 0.7153(0.7538) Grad: 37235.1328  LR: 0.00000626  \n","Epoch: [3][900/2727] Elapsed 14m 29s (remain 29m 21s) Loss: 0.6704(0.7529) Grad: 28333.7637  LR: 0.00000604  \n","Epoch: [3][1000/2727] Elapsed 16m 5s (remain 27m 45s) Loss: 0.6963(0.7535) Grad: 37370.4336  LR: 0.00000582  \n","Epoch: [3][1100/2727] Elapsed 17m 42s (remain 26m 8s) Loss: 0.7617(0.7538) Grad: 66856.8516  LR: 0.00000560  \n","Epoch: [3][1200/2727] Elapsed 19m 18s (remain 24m 31s) Loss: 0.8257(0.7532) Grad: 107132.5000  LR: 0.00000538  \n","Epoch: [3][1300/2727] Elapsed 20m 54s (remain 22m 55s) Loss: 0.7500(0.7533) Grad: 59630.6133  LR: 0.00000516  \n","Epoch: [3][1400/2727] Elapsed 22m 31s (remain 21m 19s) Loss: 0.7241(0.7525) Grad: 32177.7891  LR: 0.00000495  \n","Epoch: [3][1500/2727] Elapsed 24m 7s (remain 19m 42s) Loss: 0.7207(0.7519) Grad: 28337.9961  LR: 0.00000474  \n","Epoch: [3][1600/2727] Elapsed 25m 44s (remain 18m 6s) Loss: 0.8418(0.7514) Grad: 64473.8945  LR: 0.00000453  \n","Epoch: [3][1700/2727] Elapsed 27m 20s (remain 16m 29s) Loss: 0.8145(0.7510) Grad: 59578.5000  LR: 0.00000432  \n","Epoch: [3][1800/2727] Elapsed 28m 57s (remain 14m 53s) Loss: 0.7397(0.7508) Grad: 70542.9531  LR: 0.00000412  \n","Epoch: [3][1900/2727] Elapsed 30m 33s (remain 13m 16s) Loss: 0.7046(0.7509) Grad: 24908.0234  LR: 0.00000392  \n","Epoch: [3][2000/2727] Elapsed 32m 10s (remain 11m 40s) Loss: 0.7051(0.7510) Grad: 31201.4355  LR: 0.00000372  \n","Epoch: [3][2100/2727] Elapsed 33m 46s (remain 10m 3s) Loss: 0.7007(0.7506) Grad: 35396.5547  LR: 0.00000353  \n","Epoch: [3][2200/2727] Elapsed 35m 22s (remain 8m 27s) Loss: 0.6929(0.7503) Grad: 35054.6523  LR: 0.00000334  \n","Epoch: [3][2300/2727] Elapsed 36m 59s (remain 6m 50s) Loss: 0.6621(0.7502) Grad: 27094.5234  LR: 0.00000315  \n","Epoch: [3][2400/2727] Elapsed 38m 35s (remain 5m 14s) Loss: 0.7642(0.7502) Grad: 82784.0312  LR: 0.00000297  \n","Epoch: [3][2500/2727] Elapsed 40m 12s (remain 3m 37s) Loss: 0.7217(0.7500) Grad: 19546.0059  LR: 0.00000279  \n","Epoch: [3][2600/2727] Elapsed 41m 48s (remain 2m 1s) Loss: 0.7417(0.7497) Grad: 57482.2969  LR: 0.00000262  \n","Epoch: [3][2700/2727] Elapsed 43m 25s (remain 0m 25s) Loss: 0.7173(0.7495) Grad: 31340.7422  LR: 0.00000245  \n","Epoch: [3][2726/2727] Elapsed 43m 50s (remain 0m 0s) Loss: 0.7446(0.7494) Grad: 37061.7383  LR: 0.00000240  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Score: 0.8303\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/2727] Elapsed 0m 1s (remain 54m 47s) Loss: 0.6597(0.6597) Grad: nan  LR: 0.00000240  \n","Epoch: [4][100/2727] Elapsed 1m 37s (remain 42m 18s) Loss: 0.7104(0.7318) Grad: 36892.8945  LR: 0.00000224  \n","Epoch: [4][200/2727] Elapsed 3m 14s (remain 40m 38s) Loss: 0.7188(0.7374) Grad: 39041.6367  LR: 0.00000208  \n","Epoch: [4][300/2727] Elapsed 4m 50s (remain 39m 1s) Loss: 0.6982(0.7374) Grad: 26439.0215  LR: 0.00000193  \n","Epoch: [4][400/2727] Elapsed 6m 26s (remain 37m 24s) Loss: 0.6948(0.7360) Grad: 10435.3584  LR: 0.00000178  \n","Epoch: [4][500/2727] Elapsed 8m 3s (remain 35m 47s) Loss: 0.7441(0.7372) Grad: 44130.4180  LR: 0.00000163  \n","Epoch: [4][600/2727] Elapsed 9m 39s (remain 34m 10s) Loss: 0.7603(0.7363) Grad: 36470.7773  LR: 0.00000150  \n","Epoch: [4][700/2727] Elapsed 11m 16s (remain 32m 34s) Loss: 0.7905(0.7356) Grad: 38026.0820  LR: 0.00000136  \n","Epoch: [4][800/2727] Elapsed 12m 52s (remain 30m 57s) Loss: 0.7427(0.7347) Grad: 38112.7422  LR: 0.00000124  \n","Epoch: [4][900/2727] Elapsed 14m 29s (remain 29m 21s) Loss: 0.7217(0.7334) Grad: 62711.6328  LR: 0.00000111  \n","Epoch: [4][1000/2727] Elapsed 16m 5s (remain 27m 44s) Loss: 0.8081(0.7336) Grad: 84174.7266  LR: 0.00000100  \n","Epoch: [4][1100/2727] Elapsed 17m 41s (remain 26m 8s) Loss: 0.7446(0.7331) Grad: 22816.0332  LR: 0.00000089  \n","Epoch: [4][1200/2727] Elapsed 19m 18s (remain 24m 31s) Loss: 0.6899(0.7325) Grad: 14930.3057  LR: 0.00000078  \n","Epoch: [4][1300/2727] Elapsed 20m 55s (remain 22m 55s) Loss: 0.8125(0.7326) Grad: 111447.0625  LR: 0.00000069  \n","Epoch: [4][1400/2727] Elapsed 22m 31s (remain 21m 19s) Loss: 0.7017(0.7328) Grad: 9333.3418  LR: 0.00000060  \n","Epoch: [4][1500/2727] Elapsed 24m 7s (remain 19m 42s) Loss: 0.7549(0.7323) Grad: 94270.4141  LR: 0.00000051  \n","Epoch: [4][1600/2727] Elapsed 25m 44s (remain 18m 6s) Loss: 0.7676(0.7321) Grad: 28417.0293  LR: 0.00000043  \n","Epoch: [4][1700/2727] Elapsed 27m 20s (remain 16m 29s) Loss: 0.7119(0.7317) Grad: 66035.8750  LR: 0.00000036  \n","Epoch: [4][1800/2727] Elapsed 28m 57s (remain 14m 53s) Loss: 1.0059(0.7321) Grad: 71955.1953  LR: 0.00000029  \n","Epoch: [4][1900/2727] Elapsed 30m 33s (remain 13m 16s) Loss: 0.8950(0.7324) Grad: 97430.1875  LR: 0.00000023  \n","Epoch: [4][2000/2727] Elapsed 32m 10s (remain 11m 40s) Loss: 0.7451(0.7320) Grad: 23548.8359  LR: 0.00000018  \n","Epoch: [4][2100/2727] Elapsed 33m 46s (remain 10m 3s) Loss: 0.6948(0.7317) Grad: 23968.9824  LR: 0.00000013  \n","Epoch: [4][2200/2727] Elapsed 35m 22s (remain 8m 27s) Loss: 0.6626(0.7316) Grad: 9506.5410  LR: 0.00000010  \n","Epoch: [4][2300/2727] Elapsed 36m 59s (remain 6m 50s) Loss: 0.7212(0.7315) Grad: 38426.4219  LR: 0.00000006  \n","Epoch: [4][2400/2727] Elapsed 38m 35s (remain 5m 14s) Loss: 0.7271(0.7314) Grad: 17789.0625  LR: 0.00000004  \n","Epoch: [4][2500/2727] Elapsed 40m 12s (remain 3m 37s) Loss: 0.8960(0.7315) Grad: 49501.4727  LR: 0.00000002  \n","Epoch: [4][2600/2727] Elapsed 41m 48s (remain 2m 1s) Loss: 0.6587(0.7314) Grad: 57293.3320  LR: 0.00000001  \n","Epoch: [4][2700/2727] Elapsed 43m 24s (remain 0m 25s) Loss: 0.6465(0.7314) Grad: 4232.6528  LR: 0.00000000  \n","Epoch: [4][2726/2727] Elapsed 43m 50s (remain 0m 0s) Loss: 0.7412(0.7315) Grad: 99410.9844  LR: 0.00000000  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - Score: 0.8308\n","========== fold: 2 result ==========\n","Score: 0.8340\n","========== fold: 3 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/2716] Elapsed 0m 2s (remain 95m 12s) Loss: 1.8076(1.8076) Grad: nan  LR: 0.00000003  \n","Epoch: [1][100/2716] Elapsed 1m 38s (remain 42m 29s) Loss: 2.3828(1.7910) Grad: 107344.9766  LR: 0.00000303  \n","Epoch: [1][200/2716] Elapsed 3m 15s (remain 40m 41s) Loss: 1.4023(1.7267) Grad: 36845.7070  LR: 0.00000603  \n","Epoch: [1][300/2716] Elapsed 4m 51s (remain 39m 0s) Loss: 0.9370(1.5450) Grad: 18123.0879  LR: 0.00000903  \n","Epoch: [1][400/2716] Elapsed 6m 28s (remain 37m 20s) Loss: 1.2266(1.4327) Grad: 27023.4512  LR: 0.00001203  \n","Epoch: [1][500/2716] Elapsed 8m 4s (remain 35m 42s) Loss: 0.8345(1.3472) Grad: 7761.8481  LR: 0.00001500  \n","Epoch: [1][600/2716] Elapsed 9m 41s (remain 34m 4s) Loss: 0.7749(1.2834) Grad: 8061.4043  LR: 0.00001500  \n","Epoch: [1][700/2716] Elapsed 11m 17s (remain 32m 27s) Loss: 0.7534(1.2328) Grad: 11319.3525  LR: 0.00001499  \n","Epoch: [1][800/2716] Elapsed 12m 53s (remain 30m 50s) Loss: 0.9189(1.1903) Grad: 19032.8945  LR: 0.00001497  \n","Epoch: [1][900/2716] Elapsed 14m 30s (remain 29m 13s) Loss: 0.7993(1.1569) Grad: 7408.0615  LR: 0.00001494  \n","Epoch: [1][1000/2716] Elapsed 16m 6s (remain 27m 36s) Loss: 0.9990(1.1320) Grad: 9606.2158  LR: 0.00001491  \n","Epoch: [1][1100/2716] Elapsed 17m 43s (remain 25m 59s) Loss: 0.7998(1.1099) Grad: 9440.4834  LR: 0.00001488  \n","Epoch: [1][1200/2716] Elapsed 19m 19s (remain 24m 22s) Loss: 0.7397(1.0931) Grad: 8453.1553  LR: 0.00001483  \n","Epoch: [1][1300/2716] Elapsed 20m 56s (remain 22m 46s) Loss: 1.0293(1.0751) Grad: 12423.0957  LR: 0.00001478  \n","Epoch: [1][1400/2716] Elapsed 22m 32s (remain 21m 9s) Loss: 0.8267(1.0621) Grad: 11302.1836  LR: 0.00001472  \n","Epoch: [1][1500/2716] Elapsed 24m 8s (remain 19m 32s) Loss: 0.7988(1.0498) Grad: 3976.6313  LR: 0.00001466  \n","Epoch: [1][1600/2716] Elapsed 25m 45s (remain 17m 56s) Loss: 1.0645(1.0400) Grad: 12977.0908  LR: 0.00001459  \n","Epoch: [1][1700/2716] Elapsed 27m 21s (remain 16m 19s) Loss: 1.0352(1.0328) Grad: 27977.6074  LR: 0.00001451  \n","Epoch: [1][1800/2716] Elapsed 28m 57s (remain 14m 42s) Loss: 0.8813(1.0246) Grad: 11626.5830  LR: 0.00001442  \n","Epoch: [1][1900/2716] Elapsed 30m 34s (remain 13m 6s) Loss: 0.9536(1.0170) Grad: 8082.6611  LR: 0.00001433  \n","Epoch: [1][2000/2716] Elapsed 32m 10s (remain 11m 29s) Loss: 0.7832(1.0093) Grad: 4886.3804  LR: 0.00001424  \n","Epoch: [1][2100/2716] Elapsed 33m 46s (remain 9m 53s) Loss: 0.9600(1.0043) Grad: 3662.6267  LR: 0.00001413  \n","Epoch: [1][2200/2716] Elapsed 35m 23s (remain 8m 16s) Loss: 0.7974(0.9980) Grad: 5188.6426  LR: 0.00001402  \n","Epoch: [1][2300/2716] Elapsed 36m 59s (remain 6m 40s) Loss: 0.8711(0.9930) Grad: 3985.7561  LR: 0.00001391  \n","Epoch: [1][2400/2716] Elapsed 38m 36s (remain 5m 3s) Loss: 0.7529(0.9874) Grad: 2743.9966  LR: 0.00001379  \n","Epoch: [1][2500/2716] Elapsed 40m 12s (remain 3m 27s) Loss: 0.8013(0.9829) Grad: 2985.2024  LR: 0.00001366  \n","Epoch: [1][2600/2716] Elapsed 41m 48s (remain 1m 50s) Loss: 0.8213(0.9792) Grad: 2682.6147  LR: 0.00001353  \n","Epoch: [1][2700/2716] Elapsed 43m 25s (remain 0m 14s) Loss: 0.9438(0.9751) Grad: 8326.0928  LR: 0.00001339  \n","Epoch: [1][2715/2716] Elapsed 43m 39s (remain 0m 0s) Loss: 0.7700(0.9744) Grad: 3314.2246  LR: 0.00001337  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Score: 0.8005\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/2716] Elapsed 0m 1s (remain 57m 0s) Loss: 0.7378(0.7378) Grad: nan  LR: 0.00001337  \n","Epoch: [2][100/2716] Elapsed 1m 37s (remain 42m 9s) Loss: 0.7764(0.8208) Grad: 14771.3320  LR: 0.00001322  \n","Epoch: [2][200/2716] Elapsed 3m 14s (remain 40m 27s) Loss: 0.7666(0.8138) Grad: 15519.3525  LR: 0.00001308  \n","Epoch: [2][300/2716] Elapsed 4m 50s (remain 38m 49s) Loss: 0.8262(0.8118) Grad: 18198.8887  LR: 0.00001292  \n","Epoch: [2][400/2716] Elapsed 6m 26s (remain 37m 11s) Loss: 0.8159(0.8075) Grad: 19502.7422  LR: 0.00001276  \n","Epoch: [2][500/2716] Elapsed 8m 2s (remain 35m 34s) Loss: 0.8184(0.8042) Grad: 27533.3613  LR: 0.00001260  \n","Epoch: [2][600/2716] Elapsed 9m 39s (remain 33m 58s) Loss: 0.7505(0.8042) Grad: 14563.5654  LR: 0.00001243  \n","Epoch: [2][700/2716] Elapsed 11m 15s (remain 32m 21s) Loss: 0.8149(0.8032) Grad: 39899.9805  LR: 0.00001225  \n","Epoch: [2][800/2716] Elapsed 12m 52s (remain 30m 46s) Loss: 0.8203(0.7991) Grad: 33227.9258  LR: 0.00001208  \n","Epoch: [2][900/2716] Elapsed 14m 28s (remain 29m 9s) Loss: 0.7964(0.7982) Grad: 22576.2109  LR: 0.00001189  \n","Epoch: [2][1000/2716] Elapsed 16m 4s (remain 27m 33s) Loss: 0.8306(0.7974) Grad: 23688.7090  LR: 0.00001171  \n","Epoch: [2][1100/2716] Elapsed 17m 41s (remain 25m 56s) Loss: 0.7046(0.7963) Grad: 14361.9355  LR: 0.00001152  \n","Epoch: [2][1200/2716] Elapsed 19m 17s (remain 24m 20s) Loss: 0.8418(0.7959) Grad: 20414.9219  LR: 0.00001132  \n","Epoch: [2][1300/2716] Elapsed 20m 53s (remain 22m 43s) Loss: 0.7524(0.7953) Grad: 16261.1191  LR: 0.00001113  \n","Epoch: [2][1400/2716] Elapsed 22m 30s (remain 21m 7s) Loss: 0.8647(0.7952) Grad: 23382.9883  LR: 0.00001093  \n","Epoch: [2][1500/2716] Elapsed 24m 6s (remain 19m 30s) Loss: 0.8516(0.7948) Grad: 36751.1562  LR: 0.00001072  \n","Epoch: [2][1600/2716] Elapsed 25m 42s (remain 17m 54s) Loss: 0.7075(0.7937) Grad: 11776.6494  LR: 0.00001052  \n","Epoch: [2][1700/2716] Elapsed 27m 19s (remain 16m 18s) Loss: 0.7427(0.7924) Grad: 14315.9395  LR: 0.00001031  \n","Epoch: [2][1800/2716] Elapsed 28m 55s (remain 14m 41s) Loss: 0.8506(0.7926) Grad: 41046.3945  LR: 0.00001009  \n","Epoch: [2][1900/2716] Elapsed 30m 31s (remain 13m 5s) Loss: 0.9629(0.7930) Grad: 70351.1719  LR: 0.00000988  \n","Epoch: [2][2000/2716] Elapsed 32m 8s (remain 11m 29s) Loss: 0.7690(0.7926) Grad: 18682.5723  LR: 0.00000966  \n","Epoch: [2][2100/2716] Elapsed 33m 44s (remain 9m 52s) Loss: 0.8232(0.7922) Grad: 82334.7812  LR: 0.00000944  \n","Epoch: [2][2200/2716] Elapsed 35m 21s (remain 8m 16s) Loss: 0.6885(0.7919) Grad: 26959.6133  LR: 0.00000922  \n","Epoch: [2][2300/2716] Elapsed 36m 57s (remain 6m 39s) Loss: 0.6958(0.7917) Grad: 24593.4316  LR: 0.00000900  \n","Epoch: [2][2400/2716] Elapsed 38m 33s (remain 5m 3s) Loss: 0.7817(0.7913) Grad: 19745.4980  LR: 0.00000878  \n","Epoch: [2][2500/2716] Elapsed 40m 9s (remain 3m 27s) Loss: 0.8721(0.7911) Grad: 35479.6797  LR: 0.00000855  \n","Epoch: [2][2600/2716] Elapsed 41m 46s (remain 1m 50s) Loss: 0.9175(0.7909) Grad: 32829.7930  LR: 0.00000833  \n","Epoch: [2][2700/2716] Elapsed 43m 22s (remain 0m 14s) Loss: 0.8711(0.7907) Grad: 42716.8906  LR: 0.00000810  \n","Epoch: [2][2715/2716] Elapsed 43m 37s (remain 0m 0s) Loss: 0.8252(0.7908) Grad: 26200.1992  LR: 0.00000807  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Score: 0.8151\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/2716] Elapsed 0m 1s (remain 53m 48s) Loss: 0.7085(0.7085) Grad: nan  LR: 0.00000807  \n","Epoch: [3][100/2716] Elapsed 1m 37s (remain 42m 11s) Loss: 0.7319(0.7602) Grad: 49062.1016  LR: 0.00000784  \n","Epoch: [3][200/2716] Elapsed 3m 14s (remain 40m 27s) Loss: 0.8511(0.7607) Grad: 62845.4922  LR: 0.00000761  \n","Epoch: [3][300/2716] Elapsed 4m 50s (remain 38m 49s) Loss: 0.7412(0.7625) Grad: 40898.5781  LR: 0.00000738  \n","Epoch: [3][400/2716] Elapsed 6m 26s (remain 37m 12s) Loss: 0.6431(0.7598) Grad: 11645.2266  LR: 0.00000716  \n","Epoch: [3][500/2716] Elapsed 8m 3s (remain 35m 36s) Loss: 0.7134(0.7605) Grad: 31255.7812  LR: 0.00000693  \n","Epoch: [3][600/2716] Elapsed 9m 39s (remain 33m 59s) Loss: 0.7881(0.7601) Grad: 42360.5508  LR: 0.00000670  \n","Epoch: [3][700/2716] Elapsed 11m 15s (remain 32m 23s) Loss: 0.7822(0.7588) Grad: 30674.6426  LR: 0.00000648  \n","Epoch: [3][800/2716] Elapsed 12m 52s (remain 30m 46s) Loss: 0.7959(0.7596) Grad: 69904.8516  LR: 0.00000625  \n","Epoch: [3][900/2716] Elapsed 14m 28s (remain 29m 9s) Loss: 0.7808(0.7604) Grad: 41057.6016  LR: 0.00000603  \n","Epoch: [3][1000/2716] Elapsed 16m 5s (remain 27m 33s) Loss: 0.7100(0.7601) Grad: 19797.9961  LR: 0.00000581  \n","Epoch: [3][1100/2716] Elapsed 17m 41s (remain 25m 56s) Loss: 0.9756(0.7607) Grad: 59293.6680  LR: 0.00000559  \n","Epoch: [3][1200/2716] Elapsed 19m 17s (remain 24m 20s) Loss: 0.7202(0.7603) Grad: 17798.0430  LR: 0.00000537  \n","Epoch: [3][1300/2716] Elapsed 20m 53s (remain 22m 43s) Loss: 0.7324(0.7602) Grad: 69934.9844  LR: 0.00000515  \n","Epoch: [3][1400/2716] Elapsed 22m 30s (remain 21m 7s) Loss: 0.8096(0.7596) Grad: 30964.2812  LR: 0.00000494  \n","Epoch: [3][1500/2716] Elapsed 24m 6s (remain 19m 30s) Loss: 0.8682(0.7594) Grad: 76860.5469  LR: 0.00000472  \n","Epoch: [3][1600/2716] Elapsed 25m 42s (remain 17m 54s) Loss: 0.7197(0.7593) Grad: 28739.2188  LR: 0.00000451  \n","Epoch: [3][1700/2716] Elapsed 27m 19s (remain 16m 18s) Loss: 0.8179(0.7596) Grad: 50454.2500  LR: 0.00000431  \n","Epoch: [3][1800/2716] Elapsed 28m 55s (remain 14m 41s) Loss: 0.9248(0.7592) Grad: 117332.6016  LR: 0.00000410  \n","Epoch: [3][1900/2716] Elapsed 30m 32s (remain 13m 5s) Loss: 0.8818(0.7595) Grad: 105830.2969  LR: 0.00000390  \n","Epoch: [3][2000/2716] Elapsed 32m 8s (remain 11m 29s) Loss: 0.7085(0.7600) Grad: 18001.9824  LR: 0.00000370  \n","Epoch: [3][2100/2716] Elapsed 33m 44s (remain 9m 52s) Loss: 0.8140(0.7596) Grad: 65573.6406  LR: 0.00000351  \n","Epoch: [3][2200/2716] Elapsed 35m 20s (remain 8m 16s) Loss: 0.7090(0.7597) Grad: 10611.7910  LR: 0.00000332  \n","Epoch: [3][2300/2716] Elapsed 36m 57s (remain 6m 39s) Loss: 0.9082(0.7597) Grad: 52769.7109  LR: 0.00000313  \n","Epoch: [3][2400/2716] Elapsed 38m 33s (remain 5m 3s) Loss: 0.7573(0.7592) Grad: 33042.4688  LR: 0.00000295  \n","Epoch: [3][2500/2716] Elapsed 40m 9s (remain 3m 27s) Loss: 0.7993(0.7591) Grad: 21785.3516  LR: 0.00000277  \n","Epoch: [3][2600/2716] Elapsed 41m 46s (remain 1m 50s) Loss: 0.7412(0.7589) Grad: 21393.8027  LR: 0.00000260  \n","Epoch: [3][2700/2716] Elapsed 43m 22s (remain 0m 14s) Loss: 0.6899(0.7591) Grad: 10629.6074  LR: 0.00000243  \n","Epoch: [3][2715/2716] Elapsed 43m 36s (remain 0m 0s) Loss: 0.8320(0.7591) Grad: 30821.9336  LR: 0.00000240  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Score: 0.8139\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/2716] Elapsed 0m 1s (remain 52m 58s) Loss: 0.7529(0.7529) Grad: nan  LR: 0.00000240  \n","Epoch: [4][100/2716] Elapsed 1m 37s (remain 42m 3s) Loss: 0.6768(0.7514) Grad: 18066.6250  LR: 0.00000224  \n","Epoch: [4][200/2716] Elapsed 3m 14s (remain 40m 27s) Loss: 0.7119(0.7471) Grad: 31430.9434  LR: 0.00000208  \n","Epoch: [4][300/2716] Elapsed 4m 50s (remain 38m 49s) Loss: 0.7617(0.7461) Grad: 27982.0449  LR: 0.00000192  \n","Epoch: [4][400/2716] Elapsed 6m 26s (remain 37m 12s) Loss: 0.8271(0.7458) Grad: 46853.1055  LR: 0.00000177  \n","Epoch: [4][500/2716] Elapsed 8m 3s (remain 35m 35s) Loss: 0.7544(0.7447) Grad: 60709.0156  LR: 0.00000163  \n","Epoch: [4][600/2716] Elapsed 9m 39s (remain 33m 58s) Loss: 0.7563(0.7425) Grad: 34475.9961  LR: 0.00000149  \n","Epoch: [4][700/2716] Elapsed 11m 15s (remain 32m 21s) Loss: 0.8130(0.7433) Grad: 37948.2578  LR: 0.00000136  \n","Epoch: [4][800/2716] Elapsed 12m 51s (remain 30m 45s) Loss: 0.7554(0.7443) Grad: 55103.6094  LR: 0.00000123  \n","Epoch: [4][900/2716] Elapsed 14m 28s (remain 29m 8s) Loss: 0.7910(0.7436) Grad: 46468.0391  LR: 0.00000111  \n","Epoch: [4][1000/2716] Elapsed 16m 4s (remain 27m 32s) Loss: 0.6484(0.7437) Grad: 12307.5176  LR: 0.00000099  \n","Epoch: [4][1100/2716] Elapsed 17m 40s (remain 25m 56s) Loss: 0.7500(0.7437) Grad: 34686.8438  LR: 0.00000088  \n","Epoch: [4][1200/2716] Elapsed 19m 17s (remain 24m 19s) Loss: 0.6992(0.7440) Grad: 37943.7891  LR: 0.00000078  \n","Epoch: [4][1300/2716] Elapsed 20m 53s (remain 22m 43s) Loss: 0.8701(0.7438) Grad: 54792.7461  LR: 0.00000068  \n","Epoch: [4][1400/2716] Elapsed 22m 29s (remain 21m 7s) Loss: 0.7944(0.7441) Grad: 80571.7969  LR: 0.00000059  \n","Epoch: [4][1500/2716] Elapsed 24m 6s (remain 19m 30s) Loss: 0.7251(0.7441) Grad: 33690.1094  LR: 0.00000050  \n","Epoch: [4][1600/2716] Elapsed 25m 42s (remain 17m 54s) Loss: 0.7412(0.7433) Grad: 63681.3672  LR: 0.00000042  \n","Epoch: [4][1700/2716] Elapsed 27m 18s (remain 16m 17s) Loss: 0.8232(0.7434) Grad: 97272.7734  LR: 0.00000035  \n","Epoch: [4][1800/2716] Elapsed 28m 55s (remain 14m 41s) Loss: 0.7183(0.7430) Grad: 31024.4219  LR: 0.00000029  \n","Epoch: [4][1900/2716] Elapsed 30m 31s (remain 13m 5s) Loss: 0.7393(0.7431) Grad: 51736.3945  LR: 0.00000023  \n","Epoch: [4][2000/2716] Elapsed 32m 7s (remain 11m 28s) Loss: 0.7271(0.7430) Grad: 14118.6602  LR: 0.00000018  \n","Epoch: [4][2100/2716] Elapsed 33m 43s (remain 9m 52s) Loss: 0.7852(0.7430) Grad: 126974.2344  LR: 0.00000013  \n","Epoch: [4][2200/2716] Elapsed 35m 20s (remain 8m 16s) Loss: 0.7642(0.7429) Grad: 100033.0312  LR: 0.00000009  \n","Epoch: [4][2300/2716] Elapsed 36m 56s (remain 6m 39s) Loss: 0.8545(0.7424) Grad: 420792.0000  LR: 0.00000006  \n","Epoch: [4][2400/2716] Elapsed 38m 32s (remain 5m 3s) Loss: 0.7246(0.7424) Grad: 29192.5918  LR: 0.00000003  \n","Epoch: [4][2500/2716] Elapsed 40m 8s (remain 3m 27s) Loss: 0.7109(0.7427) Grad: 28976.3594  LR: 0.00000002  \n","Epoch: [4][2600/2716] Elapsed 41m 45s (remain 1m 50s) Loss: 0.7300(0.7430) Grad: 30522.9941  LR: 0.00000000  \n","Epoch: [4][2700/2716] Elapsed 43m 21s (remain 0m 14s) Loss: 0.7168(0.7428) Grad: 11512.9795  LR: 0.00000000  \n","Epoch: [4][2715/2716] Elapsed 43m 36s (remain 0m 0s) Loss: 0.7310(0.7428) Grad: 38088.3164  LR: 0.00000000  \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - Score: 0.8126\n","========== fold: 3 result ==========\n","Score: 0.8151\n","========== CV ==========\n","Score: 0.8280\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['score'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'/oof_df.pkl')\n","        \n","    if CFG.wandb:\n","        wandb.finish()"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"xAo-pYP_Q0eF","executionInfo":{"status":"ok","timestamp":1654643967411,"user_tz":-540,"elapsed":16,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"name":"exp018.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3d24769f94164c998ccd05b3c5c5073c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9536eb8c39364c20ab1c12e55828d451","IPY_MODEL_38b6460a6b814b8189ef78e39422b1f9","IPY_MODEL_6d19bc209fdb4c059e93beca744181c4"],"layout":"IPY_MODEL_66c8cd20f2c64dedb83a0e8e38d64c4c"}},"9536eb8c39364c20ab1c12e55828d451":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cd81607514f4314824e7e26ef79d3b4","placeholder":"​","style":"IPY_MODEL_421ea233ec2a4f27ba179b5ca5090166","value":"Downloading: 100%"}},"38b6460a6b814b8189ef78e39422b1f9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3b1361bd284435fb098ec0a193e50fc","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4cf8ea7e2dc45f99dfad6d1e85c5d83","value":52}},"6d19bc209fdb4c059e93beca744181c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d47bdfabcea3491caa2fd7ced1b2c2bf","placeholder":"​","style":"IPY_MODEL_c51231f290dc44dbb3bf9e457ded838c","value":" 52.0/52.0 [00:00&lt;00:00, 437B/s]"}},"66c8cd20f2c64dedb83a0e8e38d64c4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cd81607514f4314824e7e26ef79d3b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"421ea233ec2a4f27ba179b5ca5090166":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3b1361bd284435fb098ec0a193e50fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4cf8ea7e2dc45f99dfad6d1e85c5d83":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d47bdfabcea3491caa2fd7ced1b2c2bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c51231f290dc44dbb3bf9e457ded838c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80f3e1ee8fac49eeb7e229b85774957c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c17733f7d6b144f19e9fcdefcd04d48e","IPY_MODEL_cea9aafb791c47eaa815232ce54416f8","IPY_MODEL_f44b5813c4824dfc8db016230bfd0039"],"layout":"IPY_MODEL_c7cd83ac7d3342f3bde12c628d861269"}},"c17733f7d6b144f19e9fcdefcd04d48e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6b0254336a242619bc58e649ff4ec45","placeholder":"​","style":"IPY_MODEL_5ebe58537b084831818cb05d20879bde","value":"Downloading: 100%"}},"cea9aafb791c47eaa815232ce54416f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a318a462bea4ef6b320e343b69d0961","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_89329d9483424bf0add62c5402224e51","value":580}},"f44b5813c4824dfc8db016230bfd0039":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2228812f1214b16a91365417e077cfe","placeholder":"​","style":"IPY_MODEL_89376cc47dca48a1843252c74f7aaa17","value":" 580/580 [00:00&lt;00:00, 6.25kB/s]"}},"c7cd83ac7d3342f3bde12c628d861269":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6b0254336a242619bc58e649ff4ec45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ebe58537b084831818cb05d20879bde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a318a462bea4ef6b320e343b69d0961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89329d9483424bf0add62c5402224e51":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2228812f1214b16a91365417e077cfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89376cc47dca48a1843252c74f7aaa17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42973ce7d913440e9d9d25b2ebda96b0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb0aae3f1a634be3b84518f78d80581d","IPY_MODEL_178a24e11fd04591bde8b091e05b08fd","IPY_MODEL_3683189ae96d45aeab9f22e9740a3b99"],"layout":"IPY_MODEL_57648f3f9e664e5186ca12c3b7615b76"}},"cb0aae3f1a634be3b84518f78d80581d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b592d44790d447b833db49f13336a25","placeholder":"​","style":"IPY_MODEL_f329410721754354b2a3e01c97a27588","value":"Downloading: 100%"}},"178a24e11fd04591bde8b091e05b08fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49a4dde53e2d4b73b5883dbb3eb04fe3","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c619abb8c90401fab3d1547f88e435a","value":2464616}},"3683189ae96d45aeab9f22e9740a3b99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_371f7d3c97f8494ebb94383eec217465","placeholder":"​","style":"IPY_MODEL_a64a734a3b2b4e2a8d068b97c8a53100","value":" 2.35M/2.35M [00:00&lt;00:00, 8.75MB/s]"}},"57648f3f9e664e5186ca12c3b7615b76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b592d44790d447b833db49f13336a25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f329410721754354b2a3e01c97a27588":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49a4dde53e2d4b73b5883dbb3eb04fe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c619abb8c90401fab3d1547f88e435a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"371f7d3c97f8494ebb94383eec217465":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a64a734a3b2b4e2a8d068b97c8a53100":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ba883d90f7049eca9dbb06ad16da049":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8148f22c19aa4829aa94f7e415378ec4","IPY_MODEL_d452c386bd764c2ea96a000a665c633d","IPY_MODEL_53ddedb0630945ad92d8474d643bf236"],"layout":"IPY_MODEL_e909d4de67b34d20a25f97b87fa75452"}},"8148f22c19aa4829aa94f7e415378ec4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae4e5d1bba1945d99e9e087450ec2e60","placeholder":"​","style":"IPY_MODEL_b267a022c9be4f84851bdc30469e3c15","value":"100%"}},"d452c386bd764c2ea96a000a665c633d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50f442e64bb047e9a2d68fa657d59a46","max":136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87e3b1b1696e416e8a5acac6b5c234e4","value":136}},"53ddedb0630945ad92d8474d643bf236":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71df11cce24e4c42b005e96b2dd87dc6","placeholder":"​","style":"IPY_MODEL_3b89e9d29f5f4104af812c81f0a25c8e","value":" 136/136 [00:00&lt;00:00,  7.82it/s]"}},"e909d4de67b34d20a25f97b87fa75452":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae4e5d1bba1945d99e9e087450ec2e60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b267a022c9be4f84851bdc30469e3c15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50f442e64bb047e9a2d68fa657d59a46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87e3b1b1696e416e8a5acac6b5c234e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71df11cce24e4c42b005e96b2dd87dc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b89e9d29f5f4104af812c81f0a25c8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31fc542ccd634eada5caa460fcb0ceeb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_552ea2bb18994288963f26c9a5115730","IPY_MODEL_491681ddb5ce4fb998663910c0e55e4f","IPY_MODEL_5d8d73bcea8d48d1846a1352fde52253"],"layout":"IPY_MODEL_125b0bea10b142dc97427e52a52fe304"}},"552ea2bb18994288963f26c9a5115730":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_573f5a13e7ec4b3d9c73dc02c299731a","placeholder":"​","style":"IPY_MODEL_08a1d8b6599b4a699073653cfec0b78c","value":"100%"}},"491681ddb5ce4fb998663910c0e55e4f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_274884040edc4a90865dbb2b9a789887","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fa66957017b4f6a9ff134cd2d5b82cb","value":36473}},"5d8d73bcea8d48d1846a1352fde52253":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_788aa14f1e8e44b082a06cca0d99de15","placeholder":"​","style":"IPY_MODEL_32d3ba3ec7eb4559835a0a6c5e8df0ba","value":" 36473/36473 [00:04&lt;00:00, 7288.78it/s]"}},"125b0bea10b142dc97427e52a52fe304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"573f5a13e7ec4b3d9c73dc02c299731a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08a1d8b6599b4a699073653cfec0b78c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"274884040edc4a90865dbb2b9a789887":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fa66957017b4f6a9ff134cd2d5b82cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"788aa14f1e8e44b082a06cca0d99de15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32d3ba3ec7eb4559835a0a6c5e8df0ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d138a7fa018c4fdf80962c5f16f4191e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e0d75e1003d4938bd977cb48e43cbe3","IPY_MODEL_48a5f1a3f4994021af7317db87331337","IPY_MODEL_7327d51b28e04ea4acc603789a516f89"],"layout":"IPY_MODEL_eb6679f5a9004591a5bf537a84df6403"}},"6e0d75e1003d4938bd977cb48e43cbe3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa4b05568429416386dd7e4d27b1b193","placeholder":"​","style":"IPY_MODEL_2ecf01462d044fc0a2811b0dc3203dde","value":"100%"}},"48a5f1a3f4994021af7317db87331337":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffece297e020461a952222d0c0e84bdb","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_698b4423afd64dae8f30b2d1930d785b","value":36473}},"7327d51b28e04ea4acc603789a516f89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a7def68913141ec83d7e24c6d80b3a8","placeholder":"​","style":"IPY_MODEL_424707f246214c8faed3e7048b4b9c0d","value":" 36473/36473 [00:10&lt;00:00, 4490.77it/s]"}},"eb6679f5a9004591a5bf537a84df6403":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa4b05568429416386dd7e4d27b1b193":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ecf01462d044fc0a2811b0dc3203dde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffece297e020461a952222d0c0e84bdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"698b4423afd64dae8f30b2d1930d785b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a7def68913141ec83d7e24c6d80b3a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"424707f246214c8faed3e7048b4b9c0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d37dc96db1743b0b33c567f8c3e0d61":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad6a82c5e754438d9ba071c2b4a791ff","IPY_MODEL_fd24b4905bca4fdb8372e23ffec85b72","IPY_MODEL_cae0420598cf493ca05934f6489a6810"],"layout":"IPY_MODEL_d7c8d81cd6ab4294a4cc70df96c5d6c6"}},"ad6a82c5e754438d9ba071c2b4a791ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7833dacc53e46f896f8acaede6943b0","placeholder":"​","style":"IPY_MODEL_f9c4c741a35f4abf9fbb55493b725744","value":"Downloading: 100%"}},"fd24b4905bca4fdb8372e23ffec85b72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed8cc56d2c1946d8a7d0cd299958132b","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58d064a3a8b6480397b4b9b950d603cb","value":873673253}},"cae0420598cf493ca05934f6489a6810":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e7b68e05c8a4a99a75d4aaf45828328","placeholder":"​","style":"IPY_MODEL_5f97d8c6f9f6462b8878630eaa2f2f30","value":" 833M/833M [00:31&lt;00:00, 50.8MB/s]"}},"d7c8d81cd6ab4294a4cc70df96c5d6c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7833dacc53e46f896f8acaede6943b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9c4c741a35f4abf9fbb55493b725744":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed8cc56d2c1946d8a7d0cd299958132b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d064a3a8b6480397b4b9b950d603cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e7b68e05c8a4a99a75d4aaf45828328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f97d8c6f9f6462b8878630eaa2f2f30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}